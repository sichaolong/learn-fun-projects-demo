{"docstore/metadata": {"ce0bd718-0c7c-4745-8250-f0e66fb55ac2": {"doc_hash": "827be29700776809915ce5f9ce6c7f762bc4d9bea4066089b93b42f5a0f9133d"}, "f98d5f19-5433-45fc-af73-d794e240d1c0": {"doc_hash": "ec691ddf240bf29e51c255e046618020bc4529388f089f92d2d6a9b0610a54b3"}, "3edd1f19-2dd5-4b3a-8df8-01b871c27a11": {"doc_hash": "e6acaf8a138fef9bc9366ad48b8b3fef9e3118c41bfcb6ff5a265758c6ff1d3e"}, "67fa196f-a8b8-4de6-ba8d-3e54846b9633": {"doc_hash": "70a806d47ebf7f5078ab9f16ed1774ea84512ee31d35b5e632bd6d821852899f"}, "f2706bea-df39-4f80-86aa-4dc5f11b0fb8": {"doc_hash": "a38475b4bd00fbf711e7ee33f4a369df3e5945718e56668cbbfab012e666a137"}, "b77e1f55-8541-4e3f-99a1-b8291351a5cd": {"doc_hash": "25258bc9c12662e6e24d3914165742c1361c9fe975f79199eba1ba19020a9430"}, "f023774c-5f55-4b36-a91e-dea71750b815": {"doc_hash": "a94c7f6fb2495bd221c35828dcb196ff79871df8beef2ff1078df0e3ee0938b1"}, "8d130e53-1c72-4594-91a2-433794be99f1": {"doc_hash": "9f496b2e05bb5181e0b71ad91e40f1684db51787898cdc6944155fa629083c57"}, "771b86d3-499e-4e2d-8236-481d001c5321": {"doc_hash": "42b43dc40b3a5025aa4dc6d3bc2a8c13bed2a51b1a888694eb950dc53ec02333"}, "097e4e9a-a6a8-4265-ab4b-9d7d7bfcd85a": {"doc_hash": "46d4e79e11544fd0c75b7c1089e1d04a25eb7b8a8a563fcf5197a68c5f9fad3a"}, "349050df-91a6-4d50-867d-2d29058055e7": {"doc_hash": "7e4b67949f6340e8cceaee442ebba2f99347929337db23bd4b4cc5b126097598"}, "87f8c58f-d6c7-4a3a-9f29-c0566561c1fd": {"doc_hash": "0e80766fbd16cd1dec5a51f9c8732f321e609388daf3b3640c9ab1b0d3566a1c"}, "aed5982e-2f0e-42e1-b4da-f3a8846242a3": {"doc_hash": "d16cd307e48d87690ae35c22a72c59059874e617bd04b3aa82061f38a1844f7f"}, "b0175c01-e7bf-4881-a84c-17fc03176bb0": {"doc_hash": "1edab3e982242d767a2b0dd73374e8093d4f851cc46a313a8725a95ac06a5f91"}, "5854a489-b825-47fc-885d-c0c07660a4c8": {"doc_hash": "463edbd8a4e082b899f8752380f1fcf7cc1f5d27fbb40b6554b7a9bb589fd911"}, "26d8284f-000d-4971-9310-caeddf0a7577": {"doc_hash": "da7227fb871d6b1cfc30f5f1c26af443d956f2e70a47f91338ea778fbf3abdc5"}, "c2d54692-48fd-4f83-b340-3d4132caafe9": {"doc_hash": "ce6352a55051ba680a76d14ed1b841de22e549db95277da0d13a3035f5b02ece"}, "ef18c06e-7007-4105-9222-5e1f2e949bb5": {"doc_hash": "6822e4afcb4e56fc68be15ab3c30d76abb3c7b5007d3505edb6eea8b4cb0a949"}, "fde98b00-085b-4177-8efb-81af16683b7e": {"doc_hash": "62c3f3f1377245a5067d143114fe99c150965d99ead8cb8dcb472fcc4ff732dc"}, "b3ecc0dc-0c1c-4d04-a591-5a4ab9669a31": {"doc_hash": "2bf54c001639c4f093f2c8e504bc607770ccee06c77714fce142e30bfb417fba"}, "f23543ad-db11-4872-bc28-df3ca2dca110": {"doc_hash": "81eccd6810c7243986aeac5ca096c78dcff7e4317c71543a723baf372d2f5b7d"}, "914f18a0-a852-4a23-968c-e01f6c7acd93": {"doc_hash": "9d498351a691cb60a4887932dec6be9e26ddf02e7877aa965b6794b4e9748235"}, "b0953e88-3f26-4e4b-a3c0-b007fecdaabe": {"doc_hash": "f2d64969c7b41dbcbd0152bfe6daa98c531b5016afeda440f188858c919ca5d6"}, "3ba96f4f-846a-473b-b4a0-36c0172da10b": {"doc_hash": "827be29700776809915ce5f9ce6c7f762bc4d9bea4066089b93b42f5a0f9133d", "ref_doc_id": "ce0bd718-0c7c-4745-8250-f0e66fb55ac2"}, "db51ee0f-80ec-4d99-95ce-c523d2a9d538": {"doc_hash": "6369671fd00c211653ef9ea00416b1c6bce3dfc9c454bb28bbad32f4bc903891", "ref_doc_id": "f98d5f19-5433-45fc-af73-d794e240d1c0"}, "2e98f203-6e9c-4257-b3a7-490d277f2873": {"doc_hash": "e63d1b536bbd33fbb7e8feceb91d354f8f96b24c17dd2bd373b0a344f7ca6a7c", "ref_doc_id": "f98d5f19-5433-45fc-af73-d794e240d1c0"}, "37402b8d-14af-4dd1-83ee-71951c1d3ad7": {"doc_hash": "145bcdb5e08045dce544498aa54ec644f952ecb92271dcb111d7ad1e2f9635e2", "ref_doc_id": "3edd1f19-2dd5-4b3a-8df8-01b871c27a11"}, "fc6adb26-a88e-40c3-b114-f2f2f0c5cc27": {"doc_hash": "7bd01637747285903294841a88555aa7779a0499b0d884c17439ac8abff3cb2c", "ref_doc_id": "3edd1f19-2dd5-4b3a-8df8-01b871c27a11"}, "3b2b1760-3113-4d92-ae3b-e8323d57174b": {"doc_hash": "0d9b67a527104aa401e1e6f1c0798a5270d729547e43a42aec98b189237894dd", "ref_doc_id": "67fa196f-a8b8-4de6-ba8d-3e54846b9633"}, "6ef87599-3af1-4b69-965e-f73164751ab3": {"doc_hash": "265e868c0ddbef2f3b6db74b8b5417a68fbe73ffc5508a673b3e424ce5dd812c", "ref_doc_id": "67fa196f-a8b8-4de6-ba8d-3e54846b9633"}, "105e3cdb-daa0-4c3d-b231-e0d8de7d0cce": {"doc_hash": "a38475b4bd00fbf711e7ee33f4a369df3e5945718e56668cbbfab012e666a137", "ref_doc_id": "f2706bea-df39-4f80-86aa-4dc5f11b0fb8"}, "c9e459f8-0a06-435e-a8ce-505af3126b5f": {"doc_hash": "bba9d13b3ee4c8cf5fca554df6ffe3d13f363f2d9693d453b45ba898be9a9ee3", "ref_doc_id": "b77e1f55-8541-4e3f-99a1-b8291351a5cd"}, "852e11a7-ab67-4075-8d68-c2d6c2b55af8": {"doc_hash": "00883d6fb8ae11c03833b22cca314ed5a89bcdca9a4c6a541a7be1f300a01949", "ref_doc_id": "b77e1f55-8541-4e3f-99a1-b8291351a5cd"}, "8eb07a0b-7edc-4691-9764-a0a29c834bef": {"doc_hash": "b67f9c034758af60ea3235f75bd8b4dec12f351ad429c1c07cfa73824c3d4180", "ref_doc_id": "f023774c-5f55-4b36-a91e-dea71750b815"}, "10659886-0ef9-43ea-afb7-0010b82cf958": {"doc_hash": "05b50cce337a8dc20d7d86c01b88bb56a6ef186953142fdba85b1996493a27bd", "ref_doc_id": "f023774c-5f55-4b36-a91e-dea71750b815"}, "288bba33-38ca-4518-b888-332f3a98e9c6": {"doc_hash": "c229930f1e42083da912f2a5499cc176586a9cc47ff8c7d81757896a6a425ea9", "ref_doc_id": "8d130e53-1c72-4594-91a2-433794be99f1"}, "1ee23d3e-8b32-4c95-aea0-77183a7758f9": {"doc_hash": "4c4e23d970cce93d78e5c2adc6d86d715683ada7b4fea267deaab6efcd83457e", "ref_doc_id": "8d130e53-1c72-4594-91a2-433794be99f1"}, "38d95827-8a0a-4e27-8ca7-16714c16d9b2": {"doc_hash": "b77971a28b2b4c21c588caf4c367ce72cd8c0b5c6de97e958d55405438471540", "ref_doc_id": "771b86d3-499e-4e2d-8236-481d001c5321"}, "54c39121-74c6-487f-bb8d-44b762ed8155": {"doc_hash": "0ee55d7980f8b5005d918849cc99c6c0d225f0db602a28004ba3bc5f8cd084ed", "ref_doc_id": "771b86d3-499e-4e2d-8236-481d001c5321"}, "bd65e5c4-bc9a-436c-a131-dc5b5dea1b68": {"doc_hash": "2d4cc7ae10e958e606854487224e6f27fddb7e5ae1e38f4579e3e5fdd062b07e", "ref_doc_id": "097e4e9a-a6a8-4265-ab4b-9d7d7bfcd85a"}, "40740452-8307-4437-a79b-e2addd4722fe": {"doc_hash": "34c94acdceb15a01611a5059f6ad076916815b7d53fb2174f502a4b62e8aa72a", "ref_doc_id": "097e4e9a-a6a8-4265-ab4b-9d7d7bfcd85a"}, "d1977870-c170-4ba1-80b8-c4034c16ea8d": {"doc_hash": "f8ff34725f4594fc1aa4c8dc6015a9f7516eb9522703f1b1ad4506b8fe17f575", "ref_doc_id": "349050df-91a6-4d50-867d-2d29058055e7"}, "8c0551c4-cc53-43d7-8f15-487e35f61e98": {"doc_hash": "fdc4ef63b1f61816f4b77bc8431ecb4228e0b343dd0fb6629e838606617f52d9", "ref_doc_id": "349050df-91a6-4d50-867d-2d29058055e7"}, "d3f0efb5-cb36-478a-a961-88bb1db140be": {"doc_hash": "f69aeaa08067d108cb6f11841548ab60b9e4f747d00069051ff3928a5c1cec32", "ref_doc_id": "87f8c58f-d6c7-4a3a-9f29-c0566561c1fd"}, "d895e3e6-67c4-4439-89cd-514f65a389ca": {"doc_hash": "8486f18d91b3f5265a63a1473698a6376ba561a5b767bb1c101857dd3e09ace1", "ref_doc_id": "87f8c58f-d6c7-4a3a-9f29-c0566561c1fd"}, "509c4d17-0f51-4517-8b28-f67c18e0d647": {"doc_hash": "d16cd307e48d87690ae35c22a72c59059874e617bd04b3aa82061f38a1844f7f", "ref_doc_id": "aed5982e-2f0e-42e1-b4da-f3a8846242a3"}, "89d7228a-693e-4105-b451-74acd9731121": {"doc_hash": "6ef6a27cbb37d6d4d04998ca6708cf7922b88954c1983019360c4f9660d254ef", "ref_doc_id": "b0175c01-e7bf-4881-a84c-17fc03176bb0"}, "2638edf1-fb56-4b40-ae1e-873292b4ec32": {"doc_hash": "7225f8d839a38a540882d3dde183e4059665bda9513b93c43c8b77952f5da88b", "ref_doc_id": "b0175c01-e7bf-4881-a84c-17fc03176bb0"}, "6fb9f7e6-c2de-42e5-a7b5-7c146b5f9991": {"doc_hash": "463edbd8a4e082b899f8752380f1fcf7cc1f5d27fbb40b6554b7a9bb589fd911", "ref_doc_id": "5854a489-b825-47fc-885d-c0c07660a4c8"}, "a460e5ee-9fb6-477d-8a06-ce57d715701e": {"doc_hash": "da7227fb871d6b1cfc30f5f1c26af443d956f2e70a47f91338ea778fbf3abdc5", "ref_doc_id": "26d8284f-000d-4971-9310-caeddf0a7577"}, "c11f32bc-429e-4a61-a751-8254b8fa7f6a": {"doc_hash": "ce6352a55051ba680a76d14ed1b841de22e549db95277da0d13a3035f5b02ece", "ref_doc_id": "c2d54692-48fd-4f83-b340-3d4132caafe9"}, "6000ce40-184d-4264-819c-c27f6e1aef91": {"doc_hash": "6822e4afcb4e56fc68be15ab3c30d76abb3c7b5007d3505edb6eea8b4cb0a949", "ref_doc_id": "ef18c06e-7007-4105-9222-5e1f2e949bb5"}, "ad010d9f-3b0f-48ac-be5c-1b5e3bab1c2e": {"doc_hash": "62c3f3f1377245a5067d143114fe99c150965d99ead8cb8dcb472fcc4ff732dc", "ref_doc_id": "fde98b00-085b-4177-8efb-81af16683b7e"}, "4f253fcb-3ebe-4493-86ca-72150c7235a4": {"doc_hash": "2bf54c001639c4f093f2c8e504bc607770ccee06c77714fce142e30bfb417fba", "ref_doc_id": "b3ecc0dc-0c1c-4d04-a591-5a4ab9669a31"}, "963a32c9-d3d7-4b82-b6ef-0d2093049872": {"doc_hash": "81eccd6810c7243986aeac5ca096c78dcff7e4317c71543a723baf372d2f5b7d", "ref_doc_id": "f23543ad-db11-4872-bc28-df3ca2dca110"}, "977e631c-1538-47f0-9392-bcedf52284a3": {"doc_hash": "9ceed3e96e006679d4c0ca2f3bb9872ad7810620a8b7fc818bf5066b88069c7b", "ref_doc_id": "914f18a0-a852-4a23-968c-e01f6c7acd93"}, "a9eedea9-ec49-4386-b2c1-171b170532cb": {"doc_hash": "80556541d485c75613e8ccf8e0ca4fbec57b8abae11f104d972d2b97ef879985", "ref_doc_id": "914f18a0-a852-4a23-968c-e01f6c7acd93"}, "f505be69-9d8e-48b1-9e8f-67412ebb7589": {"doc_hash": "f2d64969c7b41dbcbd0152bfe6daa98c531b5016afeda440f188858c919ca5d6", "ref_doc_id": "b0953e88-3f26-4e4b-a3c0-b007fecdaabe"}}, "docstore/data": {"3ba96f4f-846a-473b-b4a0-36c0172da10b": {"__data__": {"id_": "3ba96f4f-846a-473b-b4a0-36c0172da10b", "embedding": null, "metadata": {"page_label": "1", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ce0bd718-0c7c-4745-8250-f0e66fb55ac2", "node_type": "4", "metadata": {"page_label": "1", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "827be29700776809915ce5f9ce6c7f762bc4d9bea4066089b93b42f5a0f9133d", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in\nLanguage Models\nAndy Zhou1 2Kai Yan1Michal Shlapentokh-Rothman1Haohan Wang1Yu-Xiong Wang1\nAbstract\nWhile language models (LMs) have shown po-\ntential across a range of decision-making tasks,\ntheir reliance on simple acting processes limits\ntheir broad deployment as autonomous agents. In\nthis paper, we introduce Language Agent Tree\nSearch (LATS) \u2013 the first general framework that\nsynergizes the capabilities of LMs in reasoning,\nacting, and planning. By leveraging the in-context\nlearning ability of LMs, we integrate Monte Carlo\nTree Search into LATS to enable LMs as agents,\nalong with LM-powered value functions and\nself-reflections for proficient exploration and en-\nhanced decision-making. A key feature of our ap-\nproach is the incorporation of an environment for\nexternal feedback, which offers a more deliberate\nand adaptive problem-solving mechanism that sur-\npasses the constraints of existing techniques. Our\nexperimental evaluation across diverse domains,\nincluding programming, interactive question-\nanswering (QA), web navigation, and math, val-\nidates the effectiveness and generality of LATS\nin decision-making while maintaining compet-\nitive or improved reasoning performance. No-\ntably, LATS achieves state-of-the-art pass@1 ac-\ncuracy (92.7%) for programming on HumanEval\nwith GPT-4 and demonstrates gradient-free per-\nformance (average score of 75.9) comparable to\ngradient-based fine-tuning for web navigation on\nWebShop with GPT-3.5. Code can be found\nathttps://github.com/lapisrocks/\nLanguageAgentTreeSearch .\n1. Introduction\nGeneral autonomous agents capable of reasoning and\ndecision-making in a variety of environments (Wooldridge\n1University of Illinois Urbana-Champaign.2Lapis Labs. Corre-\nspondence to: Andy Zhou <andyz3@illinois.edu >.\nProceedings of the 41stInternational Conference on Machine\nLearning , Vienna, Austria. PMLR 235, 2024. Copyright 2024 by\nthe author(s).\nFigure 1. Overview of LATS. Serving as a unified framework,\nLATS leverages an external environment and an MCTS-based\nsearch algorithm to improve reasoning and decision-making.\nand Jennings, 1995) have been of longstanding interest in\nthe field of artificial intelligence. While this has tradition-\nally been studied in reinforcement learning, the recent rise\nof language models (LMs) (Brown et al., 2020; Chowdh-\nery et al., 2023; Touvron et al., 2023; OpenAI, 2023) with\nstrong reasoning and general adaptability offers an alter-\nnative paradigm. Not only have LMs excelled in standard\nnatural language processing (NLP) tasks such as summariza-\ntion (Nallapati et al., 2016) and language inference (Bow-\nman et al., 2015), but they have also been adapted to an\nincreasingly diverse set of tasks that often require advanced\ncommon-sense reasoning or quantitative skills (Cobbe et al.,\n2021; Saparov and He, 2023). In addition, LMs are capable\nof performing in complex environments that involve knowl-\nedge and reasoning, such as web navigation (Yao et al.,\n2022; Deng et al., 2023), tool-use (Schick et al., 2023), and\nopen-ended games (Fan et al., 2022).\nReasoning and acting abilities have been further improved\nby prompting techniques that augment LMs with feedback\nor observations from an external environment, as exempli-\nfied by ReAct (Yao et al., 2023b) and other work (Gao et al.,\n2023; Shinn et al., 2023). This eliminates the need to rely en-\ntirely on the base abilities of LMs, enhancing them through\nexternal tools or semantic feedback. Despite such strengths,\nthese methods are reflexive and fall short of humans\u2019 deliber-\nate and thoughtful decision-making characteristics to solve\nproblems (Sloman, 1996; Evans, 2010). In particular, they\nfail to consider multiple reasoning paths or to plan ahead.\nRecent search-guided LM work (Xie et al., 2023; Yao et al.,\n2023a; Hao et al., 2023) addresses this issue by searching\nover multiple reasoning chains. While enabling planning,\n1arXiv:2310.04406v3  [cs.AI]  6 Jun 2024", "start_char_idx": 0, "end_char_idx": 4005, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "db51ee0f-80ec-4d99-95ce-c523d2a9d538": {"__data__": {"id_": "db51ee0f-80ec-4d99-95ce-c523d2a9d538", "embedding": null, "metadata": {"page_label": "2", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f98d5f19-5433-45fc-af73-d794e240d1c0", "node_type": "4", "metadata": {"page_label": "2", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "ec691ddf240bf29e51c255e046618020bc4529388f089f92d2d6a9b0610a54b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e98f203-6e9c-4257-b3a7-490d277f2873", "node_type": "1", "metadata": {}, "hash": "52a3638af0cf9ea8f9827d559da031d9fa3ed210381a5452568ced5140f3c160", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nsuch methods operate in isolation, lacking the incorporation\nof external feedback that can improve reasoning.\nTo overcome these challenges, we propose Language Agent\nTree Search (LATS) \u2013 a unified framework for decision-\nmaking and reasoning with language models. As illustrated\nin Fig. 1, LATS synergizes LM reasoning, acting, and plan-\nning strategies by expanding ReAct (Yao et al., 2023b) into a\nsearch over a combinatorial space of possible reasoning and\nacting steps. This effort is nontrivial \u2013 adapting search algo-\nrithms to language agents and shifting from non-interactive\ntasks to interactive ones requires a substantial novel design\non nodes, prompts, and search algorithms. In particular,\nnodes and prompts must effectively store and retrieve ex-\nternal feedback, with the search algorithm incorporating\nthis information into useful heuristics for value assignment.\nIndeed, our empirical evaluation, as demonstrated on Hot-\nPotQA (Yang et al., 2018) in Sec. 5.1, reveals that a simple\ncombination of existing methods is inadequate, even failing\nto surpass internal reasoning performance, despite having\naccess to the ground truth answer from the environment.\nOurkey insight underpinning LATS is adapting Monte Carlo\nTree Search (MCTS), inspired by its success in model-based\nreinforcement learning (Silver et al., 2017) and the obser-\nvation that many LM tasks allow reverting to earlier steps ,\nto language agents, repurposing pretrained LMs as agents\nwith LM-powered value functions and self-reflections for\ncleverer exploration. Leveraging the general capabilities\nand in-context learning abilities of modern LMs, we use\nlanguage as an interface between each component, allowing\nLATS to adapt planning to environmental conditions with-\nout additional training . To the best of our knowledge, LATS\nisthe first framework that incorporates reasoning, acting,\nand planning to enhance LM performance. Notably, LATS\ndoubles the performance of ReAct (Yao et al., 2023b) on\nHotPotQA (Yang et al., 2018) and raises the average score\nby22.1on WebShop (Yao et al., 2022) with GPT-3.5. When\nused with GPT-4, LATS achieves a 92.7Pass@1 rate on\nHumanEval (Chen et al., 2021), setting the state of the art.\nOurcontributions are the following: 1) We introduce LATS,\na framework based on Monte Carlo Tree Search to construct\nthe best trajectory from sampled actions, enabling more flex-\nible and adaptive problem-solving compared with reflexive\nprompting methods. 2) We propose a novel value function\nthat guides the search process and incorporates successful\nheuristics such as self-refinement and self-consistency. 3)\nBy integrating external feedback and self-reflection, LATS\nenhances model sensibility and enables agents to learn from\nexperience, surpassing reasoning-based search methods.\nThrough experiments across diverse domains, including pro-\ngramming, interactive question-answering (QA), web navi-\ngation, and math, we demonstrate the versatility of LATS\nfor enhancing autonomous reasoning and decision-making.2. Related Work\nLMs for reasoning. For LMs, reasoning involves decom-\nposing complex inputs into sequential intermediate steps\ntowards a final answer (Cobbe et al., 2021), demonstrated\nwith chain-of-thought (CoT) prompting (Wei et al., 2022)\nand its variants (Wei et al., 2022; Kojima et al., 2022; Wang\net al., 2022). However, these methods, which create chains\nautoregressively in a single step, often suffer from error\npropagation as the number of steps increases (Guo et al.,\n2018; Chen et al., 2023b), due to compound errors. Various\nadvancements aim to mitigate this issue; some approaches,\nsuch as self-consistency (Wang et al., 2022), employ ma-\njority voting over sampled chains, while others focus on\nmulti-step decomposition, such as least-to-most prompt-\ning (Zhou et al., 2022). Recently, CoT has been improved\nwith search algorithms (Yao et al., 2023a; Hao et al., 2023;\nBesta et al., 2023) that can sample trajectories more effec-\ntively.", "start_char_idx": 0, "end_char_idx": 4061, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2e98f203-6e9c-4257-b3a7-490d277f2873": {"__data__": {"id_": "2e98f203-6e9c-4257-b3a7-490d277f2873", "embedding": null, "metadata": {"page_label": "2", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f98d5f19-5433-45fc-af73-d794e240d1c0", "node_type": "4", "metadata": {"page_label": "2", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "ec691ddf240bf29e51c255e046618020bc4529388f089f92d2d6a9b0610a54b3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db51ee0f-80ec-4d99-95ce-c523d2a9d538", "node_type": "1", "metadata": {"page_label": "2", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "6369671fd00c211653ef9ea00416b1c6bce3dfc9c454bb28bbad32f4bc903891", "class_name": "RelatedNodeInfo"}}, "text": "However, these methods, which create chains\nautoregressively in a single step, often suffer from error\npropagation as the number of steps increases (Guo et al.,\n2018; Chen et al., 2023b), due to compound errors. Various\nadvancements aim to mitigate this issue; some approaches,\nsuch as self-consistency (Wang et al., 2022), employ ma-\njority voting over sampled chains, while others focus on\nmulti-step decomposition, such as least-to-most prompt-\ning (Zhou et al., 2022). Recently, CoT has been improved\nwith search algorithms (Yao et al., 2023a; Hao et al., 2023;\nBesta et al., 2023) that can sample trajectories more effec-\ntively. Tree-of-thought (ToT) prompting (Yao et al., 2023a)\nuses DFS or BFS-based (depth/breadth-first) search guided\nby an LM-generated heuristic, while reasoning via planning\n(RAP) (Hao et al., 2023) uses MCTS with rollouts simu-\nlated by LMs. However, they rely solely on LM internal\nknowledge and cannot adapt to useful external feedback.\nLMs for acting. The strong reasoning and common-sense\nabilities of LMs have been further adapted for decision-\nmaking or acting tasks as a policy model in interactive\nenvironments. In robotics, LMs have been employed as\nhigh-level controllers of control policies (Ahn et al., 2022;\nHuang et al., 2022; Driess et al., 2023). Similar work (Baker\net al., 2022; Wang et al., 2023) has also adapted LM agents\nto complex multimodal games such as Minecraft (Guss et al.,\n2019; Fan et al., 2022). LMs are particularly useful in text-\nbased environments (Liu et al., 2018; Shridhar et al., 2020;\nLiu et al., 2024), where acting-based prompting techniques\nsuch as ReAct (Yao et al., 2023b) have seen success. Sim-\nilar to CoT, ReAct is limited by its simplicity and cannot\neffectively adapt to environment conditions. Many exten-\nsions have been proposed to address this issue, including\nself-refine (Madaan et al., 2023) and Reflexion (Shinn et al.,\n2023), which use self-improvement to enhance reasoning\nand decision-making, and AdaPlanner (Sun et al., 2023),\nwhich incorporates both positive and negative feedback.\nHowever, these methods focus on refining an individual tra-\njectory and do not consider alternative choices at each step.\nIn addition, recent work (Huang et al., 2024) has suggested\nthat LMs cannot self-correct their internal reasoning, mak-\ning it critical to use external feedback. Alternatively, to pure\ndecision-making environments, the reasoning and practical\nabilities of LMs have been enhanced by providing access\nto external tools, such as APIs, search engines, calculators,\nand other models (Schick et al., 2023; Shen et al., 2023;\nSur\u00b4\u0131s et al., 2023). We summarize prior work in Tab. 1.\nTree-based search. Tree-based search, where multiple\n2", "start_char_idx": 3427, "end_char_idx": 6157, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "37402b8d-14af-4dd1-83ee-71951c1d3ad7": {"__data__": {"id_": "37402b8d-14af-4dd1-83ee-71951c1d3ad7", "embedding": null, "metadata": {"page_label": "3", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3edd1f19-2dd5-4b3a-8df8-01b871c27a11", "node_type": "4", "metadata": {"page_label": "3", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "e6acaf8a138fef9bc9366ad48b8b3fef9e3118c41bfcb6ff5a265758c6ff1d3e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc6adb26-a88e-40c3-b114-f2f2f0c5cc27", "node_type": "1", "metadata": {}, "hash": "05b1059fdbbf47562ba4fc55f80682a651ce0baed5ca4b6ca5da952ea6f9ebe4", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nApproach Reasoning Acting Planning Self- External\nReflection Memory\nCoT (Wei et al., 2022) \u2713 \u00d7 \u00d7 \u00d7 \u00d7\nReAct (Yao et al., 2023b) \u2713 \u2713 \u00d7 \u00d7 \u00d7\nToT (Yao et al., 2023a) \u2713 \u00d7 \u2713 \u2713 \u2713\nRAP (Hao et al., 2023) \u2713 \u00d7 \u2713 \u00d7 \u2713\nSelf-Refine (Madaan et al., 2023) \u2713 \u00d7 \u00d7 \u2713 \u00d7\nBeam Search (Xie et al., 2023) \u2713 \u00d7 \u00d7 \u2713 \u00d7\nReflexion (Shinn et al., 2023) \u2713 \u2713 \u00d7 \u2713 \u2713\nLATS (Ours) \u2713 \u2713 \u2713 \u2713 \u2713\nTable 1. Summary of related work on reasoning, acting, and planning. LATS is the firstwork incorporating designs from allthree domains,\nallowing broad applicability in all corresponding tasks. We refer to reasoning as LM internal reasoning, acting as external decision-making,\nplanning as the use of a search algorithm, self-reflection as the use of LM-generated feedback, and external memory as storing past text\ncontext for future updates of the solution.\nbranches of outcomes are explored during search, is widely\nused in many planning algorithms (Swiechowski et al., 2021;\nLaValle, 1998) and reinforcement learning (RL) (Hafner\net al., 2019; Du et al., 2023; Wu et al., 2023) algorithms for\nits good exploration-exploitation trade-off. Note that though\ntree-based search necessitates an environment model that\ncan expand from an arbitrary state (V odopivec et al., 2017),\noften requiring extra training in RL (Hafner et al., 2023),\nsuch a problem does not exist for most LM tasks. This is\nbecause we can conveniently revert to any state by setting\nthe input to be the context and the corresponding previous\noutput from the LM for many tasks. Thus, we operate on the\ntree-based framework and use MCTS (Swiechowski et al.,\n2021) to fully unlock the potential of LMs. In addition, we\navoid the cost of training a value function over language\ndescriptions by leveraging the in-context learning (Brown\net al., 2020) abilities of LMs. Concurrent work (Liu et al.,\n2023) also explores combining search algorithms with LM\nagents but uses an off-the-shelf search algorithm, which\nmay not be optimal for LMs. Finally, following Yao et al.\n(2023a) and Hao et al. (2023), we note that we use planning\nandsearch algorithms interchangeably in this paper.\n3. Preliminaries\n3.1. Problem Setting and Prompting\nWe first define our problem and outline a few established\nmethods that leverage language models for reasoning or\ndecision-making. In LM reasoning or decision making,\nwe are given an input xin natural language and a pre-\ntrained language model p\u03b8(x)parameterized by \u03b8; our goal\nis to generate a final output y\u223cp\u03b8(x)that corresponds\nto the answer (reasoning) or completes the task (decision-\nmaking). Both xandyare language sequences , which are\ncomprised of a list of tokens (the basic elements of natural\nlanguage, often words), denoted as x= (x[1], . . . , x [lx])\nandy= (y[1], . . . , y [ly])where lxandlyare the length.The LM decodes text autoregressively, i.e., without other\ninputs, the probability for an LM to generate a sequence y\nis given by p\u03b8(x) =Qlx\ni=1p\u03b8(x[i]|x[1. . . i\u22121]). Usually,\nto improve reasoning, prompts are provided along with the\ninput x, which are specific instructions or few-shot input-\noutput examples. We denote the generic process where an\ninput prompt IO(x)is transformed into an output yby LM:\ny\u223cp\u03b8(prompt IO(x)).\nChain-of-thought (CoT) prompting (Wei et al., 2022)\ncaters to scenarios where the direct mapping from xtoyis\nintricate, e.g., when xis from a mathematical query or chal-\nlenging question. It hinges on creating thoughts z1, . . . , z l\nthat act as stepping stones between xandy; each thought zi\nis a language sequence.", "start_char_idx": 0, "end_char_idx": 3600, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc6adb26-a88e-40c3-b114-f2f2f0c5cc27": {"__data__": {"id_": "fc6adb26-a88e-40c3-b114-f2f2f0c5cc27", "embedding": null, "metadata": {"page_label": "3", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3edd1f19-2dd5-4b3a-8df8-01b871c27a11", "node_type": "4", "metadata": {"page_label": "3", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "e6acaf8a138fef9bc9366ad48b8b3fef9e3118c41bfcb6ff5a265758c6ff1d3e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37402b8d-14af-4dd1-83ee-71951c1d3ad7", "node_type": "1", "metadata": {"page_label": "3", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "145bcdb5e08045dce544498aa54ec644f952ecb92271dcb111d7ad1e2f9635e2", "class_name": "RelatedNodeInfo"}}, "text": ". i\u22121]). Usually,\nto improve reasoning, prompts are provided along with the\ninput x, which are specific instructions or few-shot input-\noutput examples. We denote the generic process where an\ninput prompt IO(x)is transformed into an output yby LM:\ny\u223cp\u03b8(prompt IO(x)).\nChain-of-thought (CoT) prompting (Wei et al., 2022)\ncaters to scenarios where the direct mapping from xtoyis\nintricate, e.g., when xis from a mathematical query or chal-\nlenging question. It hinges on creating thoughts z1, . . . , z l\nthat act as stepping stones between xandy; each thought zi\nis a language sequence. To employ CoT prompting, thoughts\nare extracted sequentially as zi\u223cpCoT\n\u03b8(x, z1\u00b7\u00b7\u00b7i\u22121), with\nthe final output being y\u223cpCoT\n\u03b8(x, z1\u00b7\u00b7\u00b7l).\nTree-of-thought (ToT) prompting (Yao et al., 2023a) ex-\ntends CoT prompting by exploring multiple reasoning paths\nover thoughts. It frames problems as a search over a tree,\nwhere each node s= [x, z1\u00b7i]represents a partial solution\nstate comprising the original input xand the thought se-\nquence z1\u00b7\u00b7\u00b7i. Thoughts ziare generated by proposal or\nsampling with CoT zi\u223cpCoT\n\u03b8(x, z1\u00b7\u00b7\u00b7i\u22121). Search algo-\nrithms like depth-first (DFS) or breadth-first (BFS) search\nare used to systematically explore the tree, guided by heuris-\ntics based on LM evaluations V(s)of each state.\nReAct (Yao et al., 2023b) extends language models to\ntasks where the mapping from xtoyis enhanced by or\nrequires interactions with an external environment, such\nas a game or API. This technique constructs an action\nspace \u02c6A=A\u222aZthat adds permissible actions a\u2208A\nto the reasoning traces z\u2208Zfrom CoT. Observations o\nfrom the environment are used to improve both reasoning\nand acting. To solve problems with ReAct, after each ob-\nservation, actions are generated from p\u03b8sequentially as\nai\u223cpReAct\n\u03b8 (x, o1\u00b7\u00b7\u00b7i\u22121, a1\u00b7\u00b7\u00b7i\u22121), with the final output be-\n3", "start_char_idx": 3015, "end_char_idx": 4853, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3b2b1760-3113-4d92-ae3b-e8323d57174b": {"__data__": {"id_": "3b2b1760-3113-4d92-ae3b-e8323d57174b", "embedding": null, "metadata": {"page_label": "4", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "67fa196f-a8b8-4de6-ba8d-3e54846b9633", "node_type": "4", "metadata": {"page_label": "4", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "70a806d47ebf7f5078ab9f16ed1774ea84512ee31d35b5e632bd6d821852899f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ef87599-3af1-4b69-965e-f73164751ab3", "node_type": "1", "metadata": {}, "hash": "12d5742cf5ea3ef06b1c8ddbcdc6b3092141920c29fd451d8f42ccdaf679cecd", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\ningy\u223cpReAct\n\u03b8 (x, o1\u00b7\u00b7\u00b7l, a1\u00b7\u00b7\u00b7l). In this paper, consistent\nwith other LM agent methods such as ReAct and Reflexion\n(Shinn et al., 2023), we focus on decision-making tasks\nwhere reverting between iterations is feasible .\nWhile the previously described prompting techniques im-\nprove LM performance on reasoning tasks, they falter on\ndifficult tasks that involve multifaceted decision-making\ndue to several shortcomings: 1) Flexibility : Base prompting\ndesigns (CoT or ReAct) autoregressively sample from the\nLM, neglecting potential alternative continuations from spe-\ncific states. 2) Sensibility : Reasoning-based methods (CoT,\nRAP (Hao et al., 2023), or ToT) rely solely on the inter-\nnal representations of the LM and cannot consider external\nobservations. This dependency risks fact hallucination and\nerror propagation while setting a performance ceiling. 3)\nAdaptability : Current planning strategies (RAP or ToT) use\nsimple search algorithms such as BFS or cannot leverage\nenvironmental feedback to improve planning. Additionally,\nthe agent is static and cannot reuse previous experience or\nlearn from trial and error. While RAP also adopts MCTS, it\nis constrained to tasks where the LM can become a world\nmodel and accurately predict states. These shortcomings\nlimit the ability of LMs to be deployed as general problem-\nsolving agents and form the motivation for LATS.\n3.2. Monte Carlo Tree Search (MCTS)\nMonte Carlo Tree Search (MCTS) is a heuristic search al-\ngorithm that is proved successful on many decision-making\nenvironments, such as Atari (Ye et al., 2021) and Go (Silver\net al., 2016). MCTS builds a decision tree where every node\nin the tree is a state and edge is an action. MCTS runs for k\nepisodes; for each episode, it starts from the root (i.e., initial\nstate) and iteratively conducts two steps to expand the tree:\n1)Expansion , where multiple children states sare explored\nfrom the current parent state pby sampling nactions, and 2)\nSelection , where the children with the highest UCT (Upper\nConfidence bounds applied to Trees) (Kocsis and Szepesv \u00b4ari,\n2006) value is selected for expansion by the next iteration.\nThe UCT of a child state sis calculated as follows:\nUCT (s) =V(s) +ws\nlnN(p)\nN(s), (1)\nwhere N(s)is the number of visits to a node s,V(s)is the\nvalue function (expected return) from the subtree of s,wis\nthe exploration weight, and pis the parent node of s. When\nthe end of an episode is reached, a backpropagation is car-\nried out: the return ris used for updating every V(s)along\nthe path with the formula V(s) =Vold(s)(N(s)\u22121)+r\nN(s), where\nVold(s)is the old value function. Normally, the major short-\ncoming of MCTS is that it requires an environment model to\nundo previous steps and form a searching tree, which could\nbe a strong assumption. However, this limitation does not\nexist for many LM tasks, as we can conveniently reset toany step by simply copy-pasting historical text input. Such\na special property is the key motivation of our work.\n4. Unifying Reasoning, Acting, and Planning\n4.1. LM Agent\nDepending on the base prompting framework design, LATS\nsupports sequential reasoning or decision-making tasks. At\ntime step t, an agent receives an observation ot\u2208Ofrom\nthe environment and takes an action at\u2208Afollowing some\npolicy \u03c0(at|x, o1\u00b7\u00b7\u00b7t\u22121, a1\u00b7\u00b7\u00b7t\u22121). We initialize the agent\nwithp\u03b8to leverage the useful language representations of\nan LM as a base decision-maker. We follow the ReAct in-\nstantiation, in which the action space \u02c6A=A\u222aZconsists\nof both the space of permissible actions Aand the language\nspace of reasoning traces Z. Actions directly affect the envi-\nronment and result in observation, while thoughts are used\nto formalize decisions by organizing information, planning\nfuture actions, or injecting internal knowledge.", "start_char_idx": 0, "end_char_idx": 3876, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6ef87599-3af1-4b69-965e-f73164751ab3": {"__data__": {"id_": "6ef87599-3af1-4b69-965e-f73164751ab3", "embedding": null, "metadata": {"page_label": "4", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "67fa196f-a8b8-4de6-ba8d-3e54846b9633", "node_type": "4", "metadata": {"page_label": "4", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "70a806d47ebf7f5078ab9f16ed1774ea84512ee31d35b5e632bd6d821852899f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3b2b1760-3113-4d92-ae3b-e8323d57174b", "node_type": "1", "metadata": {"page_label": "4", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "0d9b67a527104aa401e1e6f1c0798a5270d729547e43a42aec98b189237894dd", "class_name": "RelatedNodeInfo"}}, "text": "4. Unifying Reasoning, Acting, and Planning\n4.1. LM Agent\nDepending on the base prompting framework design, LATS\nsupports sequential reasoning or decision-making tasks. At\ntime step t, an agent receives an observation ot\u2208Ofrom\nthe environment and takes an action at\u2208Afollowing some\npolicy \u03c0(at|x, o1\u00b7\u00b7\u00b7t\u22121, a1\u00b7\u00b7\u00b7t\u22121). We initialize the agent\nwithp\u03b8to leverage the useful language representations of\nan LM as a base decision-maker. We follow the ReAct in-\nstantiation, in which the action space \u02c6A=A\u222aZconsists\nof both the space of permissible actions Aand the language\nspace of reasoning traces Z. Actions directly affect the envi-\nronment and result in observation, while thoughts are used\nto formalize decisions by organizing information, planning\nfuture actions, or injecting internal knowledge. The exact\ninstantiation of the action space depends on the particular\nenvironment \u2013 for decision-making tasks actions might con-\nsist of commands on a website, while for reasoning tasks\nthe action space might be limited to a few external tools or\nAPIs. In environments without feedback, such as reasoning\ntasks, we use CoT as the base prompting framework.\nInstead of greedily decoding one trajectory or solution, we\nsample nactions from p\u03b8using the current state. This is\nbased on the intuition that for complex decision-making\ntasks, there is likely to be a range of potential trajectories or\nreasoning paths that are correct (Evans, 2010). Sampling a\ndiverse set of candidates at each step mitigates the stochastic\nnature of LM text generation and enables greater exploration\nin both the decision-making and reasoning space. We wrap\np\u03b8within our proposed search algorithm to deliberately\nconstruct the best trajectory from sampled actions.\n4.2. LATS\nThe main component of LATS is a search algorithm that\ncontrols the problem-solving process with planning. To find\nthe most promising trajectory and systemically balance ex-\nploration with exploitation, we adopt a variant of MCTS that\nframes decision-making as a tree search, in which each node\ns= [x, a1\u00b7\u00b7\u00b7i, o1\u00b7\u00b7\u00b7i]represents a state comprising the origi-\nnal input x, action sequence a1\u00b7i, and observation sequence\no1\u00b7i, where iis a token in the text sequence.\nOur main technical contribution is adapting MCTS to lan-\nguage agents . LATS repurposes p\u03b8as an agent, state evalua-\ntor, and feedback generator, leveraging the useful language\nrepresentations of modern LMs to facilitate planning. While\nstandard MCTS and RAP (Hao et al., 2023) rely on internal\ndynamics models to facilitate simulation, LATS uses envi-\nronment interaction and does not require a world model. As\n4", "start_char_idx": 3079, "end_char_idx": 5705, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "105e3cdb-daa0-4c3d-b231-e0d8de7d0cce": {"__data__": {"id_": "105e3cdb-daa0-4c3d-b231-e0d8de7d0cce", "embedding": null, "metadata": {"page_label": "5", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f2706bea-df39-4f80-86aa-4dc5f11b0fb8", "node_type": "4", "metadata": {"page_label": "5", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "a38475b4bd00fbf711e7ee33f4a369df3e5945718e56668cbbfab012e666a137", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nFigure 2. Overview of the six operations in LATS. A node is selected ,expanded ,evaluated , then simulated until a terminal node is reached,\nand then the resulting value is backpropagated . If the trajectory fails, a reflection is generated and used as additional context for future\ntrials. These operations are performed in succession until the budget is reached or the task is successful.\ndepicted in Fig. 2, LATS consists of a series of operations\n\u2013selection, expansion, evaluation, simulation, backpropa-\ngation, and reflection \u2013 performed in succession until the\ntask is successfully completed or a computational limit is\nreached after sampling ktrajectories. The full pseudocode\nof LATS can be found in Sec. A in the Appendix.\nSelection. In the first operation, the algorithm identifies\na segment of the current tree most suitable for subsequent\nexpansion. Starting from the root node, denoted as the initial\nstates0, a child node is selected at each tree level until a leaf\nnode is reached. To balance exploration and exploitation,\nwe use the UCT algorithm as shown in Eq. 1.\nExpansion. After selecting a node, the second operation\nexpands the tree by sampling nactions from p\u03b8, as described\nin the prior section. The environment receives each action\nand returns corresponding feedback as an observation. This\nresults in nnew child nodes added to the tree. This tree is\nstored in an external long-term memory structure.\nEvaluation. The third operation assigns a scalar value to\neach new child node for selection and backpropagation.\nThis value effectively quantifies the agent\u2019s progress in task\ncompletion, serving as a heuristic to steer the search algo-\nrithm towards the most promising regions of the tree. As\nLATS does not involve training, we propose a novel value\nfunction for this setting based on two components: (1) a\nself-generated LM score and (2) a self-consistency score.\nInspired by ToT, we repurpose p\u03b8into a value function by\nprompting it to reason about a given state. To obtain a scalar\nvalue, we instruct p\u03b8to end its reasoning trace with a score\nindicating the correctness of the trajectory. Our key distinc-\ntion from ToT is that we obtain this value after obtaining\nthe environmental feedback, improving value assignment.\nThis also enables scaling to more challenging environments,as it is difficult for LMs to improve their responses with-\nout external feedback (Huang et al., 2024). Additionally,\nto further improve value assignment, we introduce an ad-\nditional heuristic based on self-consistency (Wang et al.,\n2022), in which actions sampled multiple times at the same\nstate tend to be more accurate. This results in the overall\nvalue function:\nV(s) =\u03bb\u2217LM(s) + (1\u2212\u03bb)\u2217SC(s), (2)\nwhere \u03bbis a hyperparameter. Notably, our method offers\nenhanced flexibility over programmed heuristics (Campbell\net al., 2002) and greater efficiency than learned heuristics\n(Silver et al., 2017).\nSimulation. The fourth operation expands the currently se-\nlected node until a terminal state is reached. At each depth\nlevel, we sample and evaluate nodes with the same opera-\ntions but prioritize nodes of the highest value. Reaching a\nterminal state provides objective feedback on the correct-\nness of a trajectory. If the task is completed successfully,\nthen LATS terminates the search. If the solution is partially\nsuccessful or unsuccessful, then we perform two additional\noperations as described below. The success of a trajectory is\ndetermined by the design of the specific environment, such\nas finalizing a purchase in web navigation environments.\nBackpropagation. This operation updates the values of the\ntree based on the outcome of a trajectory. For each node\ns0, s1, . . . , s lin the trajectory from root (initial state s0)\nof the searching tree to leaf (terminal state sl), its value is\nupdated to reflect the outcome of the simulation by N(si) =\nN(si\u22121)+1 andV(si) =V(si\u22121)N(si\u22121)+r\nN(si), where ris the\nreward. These updated values are used in the UCT formula\n(Eq. 1) to guide the selection of the next node.\nReflection. In addition to the environmental feedback, we\nleverage self-reflection to further refine the decision-making\n5", "start_char_idx": 0, "end_char_idx": 4243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c9e459f8-0a06-435e-a8ce-505af3126b5f": {"__data__": {"id_": "c9e459f8-0a06-435e-a8ce-505af3126b5f", "embedding": null, "metadata": {"page_label": "6", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b77e1f55-8541-4e3f-99a1-b8291351a5cd", "node_type": "4", "metadata": {"page_label": "6", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "25258bc9c12662e6e24d3914165742c1361c9fe975f79199eba1ba19020a9430", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "852e11a7-ab67-4075-8d68-c2d6c2b55af8", "node_type": "1", "metadata": {}, "hash": "bc526a515c47f6c11171a19acd7cc3e603733fc645f603fa65580ead54be94f6", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method HotpotQA (EM) \u2191\nBase LM 0.32\nCoT (Wei et al., 2022) 0.34\nCoT - SC (Wang et al., 2022) 0.38\nToT (Yao et al., 2023a) 0.55\nRAP (Hao et al., 2023) 0.60\nRAP ( n= 10 ) 0.60\nLATS (CoT) 0.62\nTable 2. GPT-3.5 reasoning -based prompting results on HotpotQA.\nLATS achieves the highest exact match (EM) for reasoning. We\nsample n= 5nodes during expansion and k= 50 trajectories.\nprocess (Shinn et al., 2023; Madaan et al., 2023). Upon\nencountering an unsuccessful terminal node, p\u03b8is prompted\nwith the trajectory and final reward to provide a verbal self-\nreflection that summarizes the errors in the reasoning or\nacting process and proposes superior alternatives. We store\nboth failed trajectories and corresponding reflections in the\nmemory. In subsequent iterations, these are integrated as\nadditional context to the agent and value function, refining\nboth through in-context learning. This imparts a semantic\ngradient signal more useful than a scalar value, enabling\nthe agent to learn from trial and error without the cost of\nexpensive optimization such as reinforcement learning.\nDiscussion. Conceptually, LATS has several notable advan-\ntages as a general framework for reasoning and decision-\nmaking with LM agents. (1) Generality : LATS supports\nboth reasoning and decision-making tasks by defining a\nshared space of thoughts and actions. (2) Deliberation :\nLeveraging MCTS and LM value function in LATS en-\nsures a principled search that selects options with high value\nwhile exploring promising alternatives. (3) Adaptability :\nIncorporating external feedback through observations and\nself-reflection in LATS enables greater adaptation during\nproblem-solving. (4) Flexibility : LATS can accommodate\ndifferent scenarios, environments, and resource stipulations\nby modifying state design and tree dimensions. (5) Modu-\nlarity : The base LM agent, reflection generator, and value\nfunction can be independently altered and adapted to indi-\nvidual LM properties.\n5. Experiments\nTo demonstrate the general applicability of LATS, we eval-\nuate our method on a variety of domains that require rea-\nsoning and acting: programming (Chen et al., 2021; Austin\net al., 2022), HotPotQA (Yang et al., 2018), WebShop (Yao\net al., 2022), and Game of 24 (Yao et al., 2023a).Prompt Method HotpotQA (EM) \u2191\nReAct (Yao et al., 2023b) 0.32\nReAct (best of k) 0.38\nReflexion (Shinn et al., 2023) 0.51\nToT (ReAct) 0.39\nRAP (ReAct) 0.54\nLATS (ReAct) 0.63\nLATS ( n= 3) 0.58\nLATS ( n= 10 ) 0.65\nLATS (CoT + ReAct) 0.71\nTable 3. GPT-3.5 acting -based prompting results on HotpotQA.\nLATS achieves the highest exact match (EM) for acting. We\nsample n= 5nodes and use k= 50 trajectories. We also evaluate\nsampling ReAct ktimes and using both CoT and ReAct base\nprompting designs for LATS, which achieves the best performance.\nNote that LATS outperforms ToT and RAP with ReAct prompting,\nwhich are the simple adaptations of search algorithms to decision-\nmaking.\n5.1. HotPotQA\nFor a task that can be approached with both reasoning-based\nand acting-based strategies, we consider HotPotQA (Yang\net al., 2018), a multi-hop question-answering benchmark\nthat requires retrieval over two or more Wikipedia passages.\nFor the action space, in addition to LM thoughts, we follow\nthe setup from Yao et al. (2023b), which provides the agent\nwith API calls to search and retrieve information. The output\nof these API calls and self-generated reflections form the\nobservation space.", "start_char_idx": 0, "end_char_idx": 3534, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "852e11a7-ab67-4075-8d68-c2d6c2b55af8": {"__data__": {"id_": "852e11a7-ab67-4075-8d68-c2d6c2b55af8", "embedding": null, "metadata": {"page_label": "6", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b77e1f55-8541-4e3f-99a1-b8291351a5cd", "node_type": "4", "metadata": {"page_label": "6", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "25258bc9c12662e6e24d3914165742c1361c9fe975f79199eba1ba19020a9430", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c9e459f8-0a06-435e-a8ce-505af3126b5f", "node_type": "1", "metadata": {"page_label": "6", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "bba9d13b3ee4c8cf5fca554df6ffe3d13f363f2d9693d453b45ba898be9a9ee3", "class_name": "RelatedNodeInfo"}}, "text": "We\nsample n= 5nodes and use k= 50 trajectories. We also evaluate\nsampling ReAct ktimes and using both CoT and ReAct base\nprompting designs for LATS, which achieves the best performance.\nNote that LATS outperforms ToT and RAP with ReAct prompting,\nwhich are the simple adaptations of search algorithms to decision-\nmaking.\n5.1. HotPotQA\nFor a task that can be approached with both reasoning-based\nand acting-based strategies, we consider HotPotQA (Yang\net al., 2018), a multi-hop question-answering benchmark\nthat requires retrieval over two or more Wikipedia passages.\nFor the action space, in addition to LM thoughts, we follow\nthe setup from Yao et al. (2023b), which provides the agent\nwith API calls to search and retrieve information. The output\nof these API calls and self-generated reflections form the\nobservation space. Note that consistent with previous work\n(Yao et al., 2023b; Shinn et al., 2023), we use an oracle\nsetup for HotPotQA, in which the environment provides\nfeedback about the answer\u2019s correctness upon receiving an\nanswer. This enables a fair comparison between our method\nand baselines in scenarios where the quality of feedback is\nhigh, allowing us to focus our evaluation on how well the\nagent incorporates external feedback. We use a subset of\n100 questions and three few-shot examples for each method.\nFor ToT, we use DFS as the base search algorithm. For all\nmethods that involve sampling, including LATS, we sample\nk= 50 trajectories. More details are in Appendix Sec. D.\nWe evaluate internal reasoning strategies by removing ac-\ntions and observations from the context, corresponding to\nCoT (Wei et al., 2022) and its variants, CoT-SC (Wang et al.,\n2022), ToT (Yao et al., 2023a), and RAP (Hao et al., 2023).\nThese methods rely solely on the agent\u2019s existing knowledge\nto answer the question. We further consider acting-based\nmethods ReAct, Reflexion, and LATS, which augment the\nagent with the interactive API environment and primarily\nevaluate its information retrieval abilities. We also design\na simple integration of search algorithms with LM agents,\nextending ToT and RAP with ReAct prompting to handle\n6", "start_char_idx": 2706, "end_char_idx": 4848, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8eb07a0b-7edc-4691-9764-a0a29c834bef": {"__data__": {"id_": "8eb07a0b-7edc-4691-9764-a0a29c834bef", "embedding": null, "metadata": {"page_label": "7", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f023774c-5f55-4b36-a91e-dea71750b815", "node_type": "4", "metadata": {"page_label": "7", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "a94c7f6fb2495bd221c35828dcb196ff79871df8beef2ff1078df0e3ee0938b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10659886-0ef9-43ea-afb7-0010b82cf958", "node_type": "1", "metadata": {}, "hash": "35d745738873f0a7adbd1d8933102225843b3b81e657e2ff40bc46c460645a4b", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method Model Pass@1 \u2191\nCoT (Wei et al., 2022) GPT-3.5 46.9\nReAct (Yao et al., 2023b) GPT-3.5 56.9\nReflexion (Shinn et al., 2023) GPT-3.5 68.1\nToT (Yao et al., 2023a) GPT-3.5 54.4\nRAP (Hao et al., 2023) GPT-3.5 63.1\nLATS (ReAct) GPT-3.5 83.8\nBase LM GPT-4 80.1\nReflexion GPT-4 91.0\nLATS (ReAct) GPT-4 92.7\nTable 4. GPT-3.5 and GPT-4 Pass@1 accuracy on HumanEval.\nPrompting with LATS achieves the best performance. We sample\n5 solutions during expansion for 8 iterations.\nexternal observations. In addition, while LATS is designed\nfor scenarios where external feedback can enhance reason-\ning, we also implement a reasoning-only version with CoT\nas the base prompting framework. Moreover, we combine\ninternal and external reasoning in LATS by first prompting\nwith a CoT-based prompt and then switching to a ReAct-\nbased prompt upon failure. This is closer to how humans\nmight approach this task by using tools to retrieve additional\ninformation only when the answer is not already known.\nResults. We observe in Tab. 2 and Tab. 3 that both in-\nternal reasoning and external retrieval strategies perform\nwell on HotPotQA. Due to their large-scale training corpus,\nmodern LMs already encode factual knowledge and can\noften directly answer the question correctly. While CoT can\nslightly enhance performance on questions requiring rea-\nsoning, larger gains are observed with search methods ToT\nand RAP (Tab. 2, Row 4, 5), which can sample and explore\nmore outputs. We observe similar results for acting-based\nmethods. LATS surpasses ReAct, even when sampling the\nsame number of trajectories, by expanding more nodes with\nprincipled search. This is demonstrated when modifying\nn, the number of nodes expanded during each iteration. In-\ncreasing ncan consistently improve performance, although\nat greater computational and inference costs. LATS also\noutperforms RAP on internal reasoning, but has higher per-\nformance on the decision-making setting of HotPotQA than\nthe reasoning setting. Contrary to LATS, the ReAct versions\nof ToT and RAP (Tab. 3, Row 4, 5) perform even worse than\nthe reasoning-only setting of HotPotQA, which indicates\nthat the acting-based setting is more challenging and adap-\ntation of search algorithms to decision-making scenarios\nis non-trivial . Combining internal and external reasoning\nin LATS results in the highest performance, indicating the\nimportance of external feedback in augmenting reasoning\neven in tasks where the base LM can already perform.Prompt Method Pass@1 \u2191\nCoT (Wei et al., 2022) 54.9\nReAct (Wei et al., 2022) 67.0\nReflexion (Shinn et al., 2023) 70.0\nToT (Yao et al., 2023a) 65.8\nRAP (Hao et al., 2023) 71.4\nLATS (ReAct) 81.1\nTable 5. GPT-3.5 Pass@1 accuracy on MBPP. Prompting with\nLATS achieves the highest performance. We sample 5 solutions\nduring expansion for 8 iterations.\n5.2. Programming\nTo demonstrate the importance of external observations\nfor complex reasoning tasks, we evaluate the baselines\nand LATS on programming with HumanEval (Chen et al.,\n2021)1and MBPP (Austin et al., 2022). Both datasets mea-\nsure the correctness of synthesized programs in Python from\nnatural language docstrings. We use individual solutions\nas the action space and test suite and compiler feedback as\nthe external observation. We follow Chen et al. (2023a) and\nuse an LM to generate a synthetic test suite of syntactically\nvalid \u201cassert\u201d statements for each question. For each step,\nthe solution is evaluated on this test suite, and the results,\nincluding successful and failed tests and compiler output,\nare added to the context as an observation.", "start_char_idx": 0, "end_char_idx": 3672, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10659886-0ef9-43ea-afb7-0010b82cf958": {"__data__": {"id_": "10659886-0ef9-43ea-afb7-0010b82cf958", "embedding": null, "metadata": {"page_label": "7", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f023774c-5f55-4b36-a91e-dea71750b815", "node_type": "4", "metadata": {"page_label": "7", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "a94c7f6fb2495bd221c35828dcb196ff79871df8beef2ff1078df0e3ee0938b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8eb07a0b-7edc-4691-9764-a0a29c834bef", "node_type": "1", "metadata": {"page_label": "7", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "b67f9c034758af60ea3235f75bd8b4dec12f351ad429c1c07cfa73824c3d4180", "class_name": "RelatedNodeInfo"}}, "text": "Prompting with\nLATS achieves the highest performance. We sample 5 solutions\nduring expansion for 8 iterations.\n5.2. Programming\nTo demonstrate the importance of external observations\nfor complex reasoning tasks, we evaluate the baselines\nand LATS on programming with HumanEval (Chen et al.,\n2021)1and MBPP (Austin et al., 2022). Both datasets mea-\nsure the correctness of synthesized programs in Python from\nnatural language docstrings. We use individual solutions\nas the action space and test suite and compiler feedback as\nthe external observation. We follow Chen et al. (2023a) and\nuse an LM to generate a synthetic test suite of syntactically\nvalid \u201cassert\u201d statements for each question. For each step,\nthe solution is evaluated on this test suite, and the results,\nincluding successful and failed tests and compiler output,\nare added to the context as an observation.\nFor this task, the reasoning and acting baselines share an\naction space, but acting methods are able to incorporate\nobservations as additional context. For LATS, since each\naction corresponds to a complete solution, we skip the sim-\nulation step of LATS and directly use the percentage of\npassed tests as the backpropagated reward. We use k= 8\niterations, set the number of generated tests at 4, and sam-\nplen= 5solutions during expansion. After the search is\ncompleted, we select the solution with the highest value and\nevaluate it on the real test suite for the pass@1 accuracy\nevaluation. More details can be found in Appendix Sec. D.\nResults. Tab. 4 and Tab. 5 show that both search and seman-\ntic feedback are crucial for better performance. Despite not\nusing observations, ToT and RAP are competitive with Re-\nflexion. LATS has the highest performance on both datasets.\nRAP uses a search algorithm similar to LATS, which reveals\nthe importance of external feedback for difficult reasoning\ntasks such as programming. With GPT-4, using LATS sets\nthe state of the art for HumanEval, validating that LATS can\nbe used with more advanced LMs for higher performance.\n1Some baselines use 161 questions from HumanEval. We\nuse all 164 questions for LATS and find minimal performance\ndifferences, so we report baselines for both settings.\n7", "start_char_idx": 2800, "end_char_idx": 5008, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "288bba33-38ca-4518-b888-332f3a98e9c6": {"__data__": {"id_": "288bba33-38ca-4518-b888-332f3a98e9c6", "embedding": null, "metadata": {"page_label": "8", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8d130e53-1c72-4594-91a2-433794be99f1", "node_type": "4", "metadata": {"page_label": "8", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "9f496b2e05bb5181e0b71ad91e40f1684db51787898cdc6944155fa629083c57", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1ee23d3e-8b32-4c95-aea0-77183a7758f9", "node_type": "1", "metadata": {}, "hash": "f456dc216060a7ac243f966a37f32bc3f7f48020a8f6590c8366bfb208756a09", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nMethod Score\u2191SR\u2191\nReAct (Yao et al., 2023b) 53.8 28.0\nReAct (best of k) 59.1 32.0\nReflexion (Shinn et al., 2023) 64.2 35.0\nLATS (ReAct) 75.9 38.0\nIL(Yao et al., 2022) 59.9 29.1\nIL+RL (Yao et al., 2022) 62.4 28.7\nFine-tuning (Furuta et al., 2024) 67.5 45.0\nExpert 82.1 59.6\nTable 6. Score and success rate (SR) on WebShop. Results are\norganized into prompting, RL-based training, and human perfor-\nmance. For the same number of iterations, LATS improves both\nscore and SR and surpasses RL-based training.\n5.3. WebShop\nFor a complex decision-making environment with practi-\ncal applications, we consider WebShop (Yao et al., 2022),\nan online shopping environment composed of a website\nwith 1.18M real-world products and 12k human instructions.\nAgents must navigate a website through a variety of com-\nmands to purchase an item matching a user specification.\nWe use the preconstructed action space of search and click\ncommands and browser feedback and reflections for the\nobservation. The performance is gauged using two metrics:\nan average score, reflecting the percentage of user-specified\nattributes met by the selected product, and a success rate,\nindicating the frequency with which the chosen product ful-\nfills all given conditions. We compare against acting-based\nprompting methods and RL-based approaches. We evaluate\non 50 instructions, expand n= 5children for LATS, and set\nk= 30 for LATS, ReAct (best of k), and Reflexion. More\ndetails and prompts are in Appendix Sec. D and Sec. G.\nResults. We find in Tab. 6 that GPT-3.5 with ReAct is\ncompetitive to imitation learning (IL) and can exceed re-\ninforcement learning techniques with stronger prompting\nstrategies. Sampling k= 30 trajectories with ReAct and\nReflexion results in a similar performance, suggesting the se-\nmantic feedback is not as helpful in complex environments\nlike WebShop. Similar to Shinn et al. (2023), we find that\ngenerated reflections are often generic and do not provide\nuseful feedback, resulting in a tendency for the agent to\nbecome stuck in local minima. However, using LATS in-\ndeed results in a noticeable improvement, indicating a more\neffective exploration for the same number of iterations.\n5.4. Ablation Study and Additional Analysis\nWe further test the reasoning ability of LATS on Game of 24,\nand also conduct additional experiments on HotPotQA to\ndemonstrate the effect of each component of LATS (resultsPrompt Method Game of 24 (Success Rate) \u2191\nCoT (Wei et al., 2022) 0.08\nReflexion (Shinn et al., 2023) 0.12\nToT (Yao et al., 2023a) 0.20\nRAP (Hao et al., 2023) 0.40\nLATS (CoT) 0.44\nTable 7. Results on Game of 24 with GPT-3.5. We sample n= 5\nnodes and k= 30 trajectories.\nPrompt Method HotPotQA (EM) \u2191\nToT (ReAct) 0.39\nRAP (ReAct) 0.54\nLATS (No LM Heuristic) 0.37\nLATS (DFS) 0.42\nLATS (No Reflection) 0.58\nLATS (ReAct) 0.63\nTable 8. Ablation results on LATS and baseline variants in Hot-\nPotQA. We use ReAct as the base prompt and sample n= 5\nchildren and k= 50 trajectories. LATS requires every component\nand operation for optimal performance.\nshown in Tab. 8). More ablations for token consumption on\nHotPotQA are in Tab. 9 in Appendix Sec. C.\nReasoning on Game of 24.", "start_char_idx": 0, "end_char_idx": 3252, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1ee23d3e-8b32-4c95-aea0-77183a7758f9": {"__data__": {"id_": "1ee23d3e-8b32-4c95-aea0-77183a7758f9", "embedding": null, "metadata": {"page_label": "8", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8d130e53-1c72-4594-91a2-433794be99f1", "node_type": "4", "metadata": {"page_label": "8", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "9f496b2e05bb5181e0b71ad91e40f1684db51787898cdc6944155fa629083c57", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "288bba33-38ca-4518-b888-332f3a98e9c6", "node_type": "1", "metadata": {"page_label": "8", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "c229930f1e42083da912f2a5499cc176586a9cc47ff8c7d81757896a6a425ea9", "class_name": "RelatedNodeInfo"}}, "text": "We sample n= 5\nnodes and k= 30 trajectories.\nPrompt Method HotPotQA (EM) \u2191\nToT (ReAct) 0.39\nRAP (ReAct) 0.54\nLATS (No LM Heuristic) 0.37\nLATS (DFS) 0.42\nLATS (No Reflection) 0.58\nLATS (ReAct) 0.63\nTable 8. Ablation results on LATS and baseline variants in Hot-\nPotQA. We use ReAct as the base prompt and sample n= 5\nchildren and k= 50 trajectories. LATS requires every component\nand operation for optimal performance.\nshown in Tab. 8). More ablations for token consumption on\nHotPotQA are in Tab. 9 in Appendix Sec. C.\nReasoning on Game of 24. To show how LATS can be\napplied to purely internal reasoning tasks, we additionally\nevaluate on Game of 24 (Yao et al., 2023a), a mathematical\nreasoning task where the agent must construct 24 out of a\nset of numbers and basic operations. We use CoT as the\nbase prompting design and employ the same operations as\nin other settings. We find in Tab. 7 that LATS outperforms\nprevious methods proposed specifically for reasoning. This\nis due to our proposed value function, which incorporates\nself-consistency as an additional heuristic.\nSelf-reflection. LATS uses self-reflection to provide addi-\ntional semantic signals for the agent. In Tab. 8 (Row 5, 6),\nwe observe a 0.05performance drop when self-reflection\nis removed from LATS, validating its usefulness. This is a\nsmaller gain than the 0.19gain that Reflexion has over Re-\nAct as shown in Tab. 3, suggesting overlap between the ques-\ntions where an answer can be improved by self-reflection\nand search. This variant outperforms RAP (ReAct), reflect-\ning our improvements to MCTS.\nSearch algorithm. MCTS is a more principled search algo-\nrithm than variants like A* (Zhuang et al., 2023) or DFS and\nis the basis for observed performance gains. We observe\nthe effects of using DFS, and incorporate the LM-based\nheuristic used in ToT in which branches with low values are\npruned. This removes the selection and backpropagation\noperations, and we observe a 0.21drop in performance in\n8", "start_char_idx": 2709, "end_char_idx": 4688, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "38d95827-8a0a-4e27-8ca7-16714c16d9b2": {"__data__": {"id_": "38d95827-8a0a-4e27-8ca7-16714c16d9b2", "embedding": null, "metadata": {"page_label": "9", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "771b86d3-499e-4e2d-8236-481d001c5321", "node_type": "4", "metadata": {"page_label": "9", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "42b43dc40b3a5025aa4dc6d3bc2a8c13bed2a51b1a888694eb950dc53ec02333", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54c39121-74c6-487f-bb8d-44b762ed8155", "node_type": "1", "metadata": {}, "hash": "06e205fa598f64d84f7e7962d917f8c54aede69ecf73d9cf83e6ecbd2d71b7b7", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nMethod Performance \u2191Sample complexity \u2193Token Consumption \u2193\nReAct (Best k= 250 ) 0.42 O(k) -\nCoT-SC ( n= 1, k= 250 ) 0.40 O(k) -\nLATS ( n= 1, k= 50 ) 0.48 O(k) -\nToT (ReAct, n= 5, k= 50 ) 0.49 O(kn) 210,215\nRAP (ReAct, n= 5, k= 50 ) 0.54 O(kn) 176,500\nLATS ( n= 5, k= 50 ) 0.63 O(kn) 173,290\nTable 9. Performance, sample complexity of different methods, average number of nodes expanded, and token consumption upon success\nby methods with tree-based search. nis the number of children nodes expanded at every step and kis the number of trajectories. LATS\nhas the same sample complexity as other methods with tree-based search and expands less nodes upon success, which indicates lower\ntoken cost.\nMethod k HotPotQA \u2191# of Nodes \u2193\nToT 10 0.34 33.97\nRAP 10 0.44 31.53\nLATS 10 0.44 28.42\nToT 30 0.39 47.54\nRAP 30 0.50 37.71\nLATS 30 0.52 34.12\nToT 50 0.49 84.05\nRAP 50 0.54 70.60\nLATS 50 0.61 66.65\nTable 10. Comparison of the cost of different methods on Hot-\nPotQA. LATS achieves the highest accuracy and the lowest av-\nerage number of nodes/states required for success at various k\ntrajectories sampled.\nTab. 8 (Row 4) when sampling the same number of nodes\nbut outperforms ToT (ReAct). Despite also benefiting from\nground-truth feedback, LATS uses it better than ToT and\nRAP and can outperform these methods. We also find in\nTab. 8 (Row 3) that LM scoring, the main component of our\nvalue function, is crucial for leveraging external feedback\nand strong performance.\nSample complexity and token consumption. One pos-\nsible concern of LATS is that the tree-structured search\nmight consume much more tokens than existing methods.\nTo further study the computational cost of LATS compared\nto prior methods, we examine the sample complexity (i.e.,\nasymptotic token cost) of all methods considered in this\npaper and count the average number of nodes expanded\nby our method and other tree-structured methods (ToT and\nRAP) upon successful search on HotPotQA. We present the\nresults in Tab. 9 and Tab. 10, which show that our method\nhas the same sample complexity as other tree-based search\nmethods and requires fewer overall tokens and states. The\ntoken cost gap will be even larger when taking failed trajec-\ntories into account, since our method has a higher success\nrate and reaches the computational budget limit less often.\nThis is also true when sampling a smaller number of trajec-\ntories; on average, LATS requires 3.55 fewer nodes thanRAP and 12.12 fewer nodes than ToT. These findings un-\nderscore our improvements to MCTS and adaptation to LM\nagents, resulting in a more principled and efficient search\nmechanism.\n6. Conclusion\nThis work introduces Language Agent Tree Search (LATS),\nthe first framework to unify reasoning, acting, and plan-\nning for enhanced LM problem-solving. LATS addresses\nkey limitations of prior prompting techniques by deliber-\nately constructing trajectories with search algorithms, in-\ncorporating external feedback, and enabling agents to learn\nfrom experience. Our evaluation demonstrates the ability\nof LATS to harness LM capabilities for various decision-\nmaking tasks while maintaining its reasoning ability without\nadditional training . The proposed synergies between search,\ninteraction, and reflection offer a versatile approach to au-\ntonomous decision-making, highlighting the potential of\nLMs as generalist agents.\nLimitations and future directions. LATS has two main\nlimitations that should be considered before its application.\nFirst, it has a higher computational cost compared to simpler\nprompting methods like ReAct or Reflexion, which may\nlimit its practicality in certain situations.", "start_char_idx": 0, "end_char_idx": 3715, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54c39121-74c6-487f-bb8d-44b762ed8155": {"__data__": {"id_": "54c39121-74c6-487f-bb8d-44b762ed8155", "embedding": null, "metadata": {"page_label": "9", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "771b86d3-499e-4e2d-8236-481d001c5321", "node_type": "4", "metadata": {"page_label": "9", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "42b43dc40b3a5025aa4dc6d3bc2a8c13bed2a51b1a888694eb950dc53ec02333", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "38d95827-8a0a-4e27-8ca7-16714c16d9b2", "node_type": "1", "metadata": {"page_label": "9", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "b77971a28b2b4c21c588caf4c367ce72cd8c0b5c6de97e958d55405438471540", "class_name": "RelatedNodeInfo"}}, "text": "6. Conclusion\nThis work introduces Language Agent Tree Search (LATS),\nthe first framework to unify reasoning, acting, and plan-\nning for enhanced LM problem-solving. LATS addresses\nkey limitations of prior prompting techniques by deliber-\nately constructing trajectories with search algorithms, in-\ncorporating external feedback, and enabling agents to learn\nfrom experience. Our evaluation demonstrates the ability\nof LATS to harness LM capabilities for various decision-\nmaking tasks while maintaining its reasoning ability without\nadditional training . The proposed synergies between search,\ninteraction, and reflection offer a versatile approach to au-\ntonomous decision-making, highlighting the potential of\nLMs as generalist agents.\nLimitations and future directions. LATS has two main\nlimitations that should be considered before its application.\nFirst, it has a higher computational cost compared to simpler\nprompting methods like ReAct or Reflexion, which may\nlimit its practicality in certain situations. Second, LATS\nassumes the ability to revert to earlier states in decision-\nmaking environments, which may not be universally ap-\nplicable in all possible environments. Despite these limi-\ntations, it is worth noting that LATS still achieves better\nperformance and efficiency compared to similar methods,\nand the number of nodes expanded at each step provides a\ntrade-off between performance and efficiency. Additionally,\nwe expect inference-time compute costs to decrease over\ntime, thereby increasing the usefulness of LATS and other\n\u201cSystem-2\u201d LM approaches. Finally, the reversion prop-\nerty is feasible in many real-world applications, opening up\nnew opportunities in the LM decision-making community.\nFuture directions include scaling LATS to more complex\nenvironments or multi-agent frameworks and improving ef-\nficiency to reduce costs. A more detailed discussion about\nthe limitations of LATS can be found in Appendix Sec. B.\n9", "start_char_idx": 2701, "end_char_idx": 4650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd65e5c4-bc9a-436c-a131-dc5b5dea1b68": {"__data__": {"id_": "bd65e5c4-bc9a-436c-a131-dc5b5dea1b68", "embedding": null, "metadata": {"page_label": "10", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "097e4e9a-a6a8-4265-ab4b-9d7d7bfcd85a", "node_type": "4", "metadata": {"page_label": "10", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "46d4e79e11544fd0c75b7c1089e1d04a25eb7b8a8a563fcf5197a68c5f9fad3a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "40740452-8307-4437-a79b-e2addd4722fe", "node_type": "1", "metadata": {}, "hash": "6ed35a7eecf271c7b7fdd8ba44a4fa289658c3190d8586e9b55d983bd7375aef", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nImpact Statement\nLATS is a framework that enhances LM performance\nthrough interactions with an environment. This improve-\nment in autonomous decision-making may facilitate harm-\nful uses of LMs. On the other hand, LATS enhances in-\nterpretability and the potential for greater alignment, as it\ninvolves high-level linguistic reasoning and actions through\nseveral rounds of decision-making and reflection rather than\nrelying on autoregressive generation. Finally, enhancing the\ncapabilities of LM agents may raise security risks, such as\nexecuting malware. We encourage further research to fully\nunderstand and mitigate the risks of LMs.\nAcknowledgements\nWe thank Daniel Campos for useful feedback on earlier ver-\nsions of this paper. This work was supported in part by NSF\nGrant 2106825, NIFA Award 2020-67021-32799, the Jump\nARCHES endowment through the Health Care Engineering\nSystems Center at Illinois and the OSF Foundation, and the\nIBM-Illinois Discovery Accelerator Institute. This work\nused NVIDIA GPUs at NCSA Delta through allocations\nCIS220014, CIS230012, and CIS230218 from the ACCESS\nprogram.\nReferences\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Cheb-\notar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan\nFu, Keerthana Gopalakrishnan, Karol Hausman, Alex\nHerzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian\nIchter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano,\nKyle Jeffrey, Sally Jesmonth, Nikhil J Joshi, Ryan Julian,\nDmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee,\nSergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter\nPastor, Jornell Quiambao, Kanishka Rao, Jarek Retting-\nhouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers,\nClayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei\nXia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, and\nAndy Zeng. Do as I can, not as I say: Grounding language\nin robotic affordances. In CoRL , 2022.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten\nBosma, Henryk Michalewski, David Dohan, Ellen Jiang,\nCarrie Cai, Michael Terry, Quoc Le, and Charles Sut-\nton. Program synthesis with large language models. In\nNeurIPS , 2022.\nBowen Baker, Ilge Akkaya, Peter Zhokhov, Joost Huizinga,\nJie Tang, Adrien Ecoffet, Brandon Houghton, Raul\nSampedro, and Jeff Clune. Video pretraining (VPT):\nLearning to act by watching unlabeled online videos. In\nNeurIPS , 2022.\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Ger-stenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz\nLehmann, Michal Podstawski, Hubert Niewiadomski, Pi-\notr Nyczyk, and Torsten Hoefler. Graph of thoughts:\nSolving elaborate problems with large language models.\narXiv:2308.09687 , 2023.\nSamuel R Bowman, Gabor Angeli, Christopher Potts, and\nChristopher D Manning. A large annotated corpus for\nlearning natural language inference. In EMNLP , 2015.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\nSandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger,\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel M.\nZiegler, Jeffrey Wu, Clemens Winter, Christopher Hesse,\nMark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam\nMcCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. Language models are few-shot learners. In\nNeurIPS , 2020.\nMurray Campbell, A Joseph Hoane Jr, and Feng-hsiung\nHsu. Deep blue.", "start_char_idx": 0, "end_char_idx": 3461, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40740452-8307-4437-a79b-e2addd4722fe": {"__data__": {"id_": "40740452-8307-4437-a79b-e2addd4722fe", "embedding": null, "metadata": {"page_label": "10", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "097e4e9a-a6a8-4265-ab4b-9d7d7bfcd85a", "node_type": "4", "metadata": {"page_label": "10", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "46d4e79e11544fd0c75b7c1089e1d04a25eb7b8a8a563fcf5197a68c5f9fad3a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd65e5c4-bc9a-436c-a131-dc5b5dea1b68", "node_type": "1", "metadata": {"page_label": "10", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "2d4cc7ae10e958e606854487224e6f27fddb7e5ae1e38f4579e3e5fdd062b07e", "class_name": "RelatedNodeInfo"}}, "text": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\nSandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger,\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel M.\nZiegler, Jeffrey Wu, Clemens Winter, Christopher Hesse,\nMark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam\nMcCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. Language models are few-shot learners. In\nNeurIPS , 2020.\nMurray Campbell, A Joseph Hoane Jr, and Feng-hsiung\nHsu. Deep blue. Artificial intelligence , 2002.\nBei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi\nLin, Jian-Guang Lou, and Weizhu Chen. CodeT: Code\ngeneration with generated tests. In ICLR , 2023a.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,\nHenrique Ponde, Jared Kaplan, Harrison Edwards, Yura\nBurda, Nicholas Joseph, Greg Brockman, Alex Ray,\nRaul Puri, Gretchen Krueger, Michael Petrov, Heidy\nKhlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\nScott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power,\nLukasz Kaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, David W. Cum-\nmings, Matthias Plappert, Fotios Chantzis, Elizabeth\nBarnes, Ariel Herbert-V oss, William H. Guss, Alex\nNichol, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nAndrew Carr, Jan Leike, Joshua Achiam, Vedant Misra,\nEvan Morikawa, Alec Radford, Matthew M. Knight,\nMiles Brundage, Mira Murati, Katie Mayer, Peter Welin-\nder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. Evaluating large lan-\nguage models trained on code. arXiv:2107.03374 , 2021.\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W.\nCohen. Program of thoughts prompting: disentangling\ncomputation from reasoning for numerical reasoning\ntasks. TMLR , 2023b. ISSN 2835-8856.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, Parker Schuh, Kensen Shi, Sasha\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker\n10", "start_char_idx": 2850, "end_char_idx": 4978, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1977870-c170-4ba1-80b8-c4034c16ea8d": {"__data__": {"id_": "d1977870-c170-4ba1-80b8-c4034c16ea8d", "embedding": null, "metadata": {"page_label": "11", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "349050df-91a6-4d50-867d-2d29058055e7", "node_type": "4", "metadata": {"page_label": "11", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "7e4b67949f6340e8cceaee442ebba2f99347929337db23bd4b4cc5b126097598", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c0551c4-cc53-43d7-8f15-487e35f61e98", "node_type": "1", "metadata": {}, "hash": "5d5a733617e328e5031ec9699df26ae8e1499cf7f49844898492d36a0c4fa76b", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nBarnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran,\nEmily Reif, Nan Du, Ben Hutchinson, Reiner Pope,\nJames Bradbury, Jacob Austin, Michael Isard, Guy Gur-\nAri, Pengcheng Yin, Toju Duke, Anselm Levskaya, San-\njay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier\nGarcia, Vedant Misra, Kevin Robinson, Liam Fedus,\nDenny Zhou, Daphne Ippolito, David Luan, Hyeontaek\nLim, Barret Zoph, Alexander Spiridonov, Ryan Sepa-\nssi, David Dohan, Shivani Agrawal, Mark Omernick,\nAndrew M. Dai, Thanumalayan Sankaranarayana Pillai,\nMarie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon\nChild, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\nXuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat,\nMichele Catasta, Jason Wei, Kathy Meier-Hellstern, Dou-\nglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. PaLM:\nScaling language modeling with pathways. JMLR , 24\n(240):1\u2013113, 2023.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark\nChen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert,\nJerry Tworek, Jacob Hilton, Reiichiro Nakano, Christo-\npher Hesse, and John Schulman. Training verifiers to\nsolve math word problems. arXiv:2110.14168 , 2021.\nXiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel\nStevens, Boshi Wang, Huan Sun, and Yu Su. Mind2Web:\nTowards a generalist agent for the web. In NeurIPS\nDatasets and Benchmarks Track , 2023.\nDanny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch,\nAakanksha Chowdhery, Brian Ichter, Ayzaan Wahid,\nJonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong\nHuang, Yevgen Chebotar, Pierre Sermanet, Daniel Duck-\nworth, Sergey Levine, Vincent Vanhoucke, Karol Haus-\nman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mor-\ndatch, and Pete Florence. PaLM-E: An embodied multi-\nmodal language model. In ICML , 2023.\nYilun Du, Mengjiao Yang, Bo Dai, Hanjun Dai, Ofir\nNachum, Joshua B. Tenenbaum, Dale Schuurmans, and\nPieter Abbeel. Learning universal policies via text-guided\nvideo generation. In NeurIPS , 2023.\nJonathan St BT Evans. Intuition and reasoning: A dual-\nprocess perspective. Psychological Inquiry , pages 313 \u2013\n326, 2010.\nLinxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar,\nYuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang,\nYuke Zhu, and Anima Anandkumar. MineDojo: Building\nopen-ended embodied agents with internet-scale knowl-\nedge. In NeurIPS Datasets and Benchmarks Track , 2022.\nHiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Mat-\nsuo, Shixiang Shane Gu, and Izzeddin Gur. Multimodal\nweb navigation with instruction-finetuned foundation\nmodels. In ICLR , 2024.Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei\nLiu, Yiming Yang, Jamie Callan, and Graham Neubig.\nPAL: Program-aided language models. In ICML , 2023.\nJiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and\nJun Wang. Long text generation via adversarial training\nwith leaked information. In AAAI , 2018.\nWilliam H. Guss, Brandon Houghton, Nicholay Topin,\nPhillip Wang, Cayden Codel, Manuela Veloso, and Rus-\nlan Salakhutdinov. MineRL: A large-scale dataset of\nMinecraft demonstrations.", "start_char_idx": 0, "end_char_idx": 3074, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c0551c4-cc53-43d7-8f15-487e35f61e98": {"__data__": {"id_": "8c0551c4-cc53-43d7-8f15-487e35f61e98", "embedding": null, "metadata": {"page_label": "11", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "349050df-91a6-4d50-867d-2d29058055e7", "node_type": "4", "metadata": {"page_label": "11", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "7e4b67949f6340e8cceaee442ebba2f99347929337db23bd4b4cc5b126097598", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1977870-c170-4ba1-80b8-c4034c16ea8d", "node_type": "1", "metadata": {"page_label": "11", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "f8ff34725f4594fc1aa4c8dc6015a9f7516eb9522703f1b1ad4506b8fe17f575", "class_name": "RelatedNodeInfo"}}, "text": "Multimodal\nweb navigation with instruction-finetuned foundation\nmodels. In ICLR , 2024.Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei\nLiu, Yiming Yang, Jamie Callan, and Graham Neubig.\nPAL: Program-aided language models. In ICML , 2023.\nJiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and\nJun Wang. Long text generation via adversarial training\nwith leaked information. In AAAI , 2018.\nWilliam H. Guss, Brandon Houghton, Nicholay Topin,\nPhillip Wang, Cayden Codel, Manuela Veloso, and Rus-\nlan Salakhutdinov. MineRL: A large-scale dataset of\nMinecraft demonstrations. In IJCAI , 2019.\nDanijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Ville-\ngas, David Ha, Honglak Lee, and James Davidson. Learn-\ning latent dynamics for planning from pixels. In ICML ,\n2019.\nDanijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timo-\nthy Lillicrap. Mastering diverse domains through world\nmodels. arXiv:2301.04104 , 2023.\nShibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen\nWang, Daisy Zhe Wang, and Zhiting Hu. Reasoning\nwith language model is planning with world model. In\nEMNLP , 2023.\nJie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven\nZheng, Adams Wei Yu, Xinying Song, and Denny Zhou.\nLarge language models cannot self-correct reasoning yet.\nInICLR , 2024.\nWenlong Huang, F. Xia, Ted Xiao, Harris Chan, Jacky\nLiang, Peter R. Florence, Andy Zeng, Jonathan Tompson,\nIgor Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah\nBrown, Tomas Jackson, Linda Luu, Sergey Levine, Karol\nHausman, and Brian Ichter. Inner monologue: Embodied\nreasoning through planning with language models. In\nCoRL , 2022.\nLevente Kocsis and Csaba Szepesv \u00b4ari. Bandit based monte-\ncarlo planning. In ECML , 2006.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka\nMatsuo, and Yusuke Iwasawa. Large language models\nare zero-shot reasoners. In NeurIPS , 2022.\nSteven M. LaValle. Rapidly-exploring random trees : A\nnew tool for path planning. The Annual Research Report ,\n1998.\nEvan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin\nShi, and Percy Liang. Reinforcement learning on web\ninterfaces using workflow-guided exploration. In ICLR ,\n2018.\nXiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu\nLei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men,\n11", "start_char_idx": 2494, "end_char_idx": 4720, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d3f0efb5-cb36-478a-a961-88bb1db140be": {"__data__": {"id_": "d3f0efb5-cb36-478a-a961-88bb1db140be", "embedding": null, "metadata": {"page_label": "12", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "87f8c58f-d6c7-4a3a-9f29-c0566561c1fd", "node_type": "4", "metadata": {"page_label": "12", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "0e80766fbd16cd1dec5a51f9c8732f321e609388daf3b3640c9ab1b0d3566a1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d895e3e6-67c4-4439-89cd-514f65a389ca", "node_type": "1", "metadata": {}, "hash": "a3c8fc6101e41be1863e36bcbc91fdb0452903ff1d3b0c1dbd8a2ff0f7eb5403", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nKejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng,\nZhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun\nZhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong,\nand Jie Tang. AgentBench: Evaluating LLMs as agents.\nInICLR , 2024.\nZhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi\nKe, Boyi Liu, and Zhaoran Wang. Reason for fu-\nture, act for now: A principled framework for au-\ntonomous LLM agents with provable sample efficiency.\narXiv:2309.17382 , 2023.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hal-\nlinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha\nDziri, Shrimai Prabhumoye, Yiming Yang, Shashank\nGupta, Bodhisattwa Prasad Majumder, Katherine Her-\nmann, Sean Welleck, Amir Yazdanbakhsh, and Peter\nClark. Self-refine: Iterative refinement with self-feedback.\nInNeurIPS , 2023.\nRamesh Nallapati, Bowen Zhou, Cicero dos Santos, Caglar\nGulcehre, and Bing Xiang. Abstractive text summariza-\ntion using sequence-to-sequence RNNs and beyond. In\nSpecial Interest Group on Natural Language Learning ,\n2016.\nOpenAI. GPT-4 technical report. arXiv:2303.08774 , 2023.\nYujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan\nYan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill\nQian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou,\nMark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.\nToolLLM: Facilitating large language models to master\n16000+ real-world APIs. In ICLR , 2024.\nAbulhair Saparov and He He. Language models are greedy\nreasoners: A systematic formal analysis of chain-of-\nthought. In ICLR , 2023.\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess `\u0131, Roberta\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Can-\ncedda, and Thomas Scialom. Toolformer: Language\nmodels can teach themselves to use tools. In NeurIPS ,\n2023.\nYongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,\nWeiming Lu, and Yueting Zhuang. HuggingGPT: Solving\nAI tasks with ChatGPT and its friends in Hugging Face.\nInNeurIPS , 2023.\nNoah Shinn, Federico Cassano, Beck Labash, Ashwin\nGopinath, Karthik Narasimhan, and Shunyu Yao. Reflex-\nion: Language agents with verbal reinforcement learning.\nInNeurIPS , 2023.\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre C \u02c6ot\u00b4e,\nYonatan Bisk, Adam Trischler, and Matthew Hausknecht.\nALFWorld: Aligning text and embodied environments\nfor interactive learning. In ICLR , 2020.David Silver, Aja Huang, Chris J. Maddison, Arthur Guez,\nL. Sifre, George van den Driessche, Julian Schrittwieser,\nIoannis Antonoglou, Vedavyas Panneershelvam, Marc\nLanctot, Sander Dieleman, Dominik Grewe, John Nham,\nNal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel,\nand Demis Hassabis. Mastering the game of Go with deep\nneural networks and tree search. Nature , 529:484\u2013489,\n2016.", "start_char_idx": 0, "end_char_idx": 2796, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d895e3e6-67c4-4439-89cd-514f65a389ca": {"__data__": {"id_": "d895e3e6-67c4-4439-89cd-514f65a389ca", "embedding": null, "metadata": {"page_label": "12", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "87f8c58f-d6c7-4a3a-9f29-c0566561c1fd", "node_type": "4", "metadata": {"page_label": "12", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "0e80766fbd16cd1dec5a51f9c8732f321e609388daf3b3640c9ab1b0d3566a1c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d3f0efb5-cb36-478a-a961-88bb1db140be", "node_type": "1", "metadata": {"page_label": "12", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "f69aeaa08067d108cb6f11841548ab60b9e4f747d00069051ff3928a5c1cec32", "class_name": "RelatedNodeInfo"}}, "text": "ALFWorld: Aligning text and embodied environments\nfor interactive learning. In ICLR , 2020.David Silver, Aja Huang, Chris J. Maddison, Arthur Guez,\nL. Sifre, George van den Driessche, Julian Schrittwieser,\nIoannis Antonoglou, Vedavyas Panneershelvam, Marc\nLanctot, Sander Dieleman, Dominik Grewe, John Nham,\nNal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel,\nand Demis Hassabis. Mastering the game of Go with deep\nneural networks and tree search. Nature , 529:484\u2013489,\n2016.\nDavid Silver, Aja Huang, Chris J. Maddison, Arthur Guez,\nL. Sifre, George van den Driessche, Julian Schrittwieser,\nIoannis Antonoglou, Vedavyas Panneershelvam, Marc\nLanctot, Sander Dieleman, Dominik Grewe, John Nham,\nNal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel,\nand Demis Hassabis. Mastering chess and Shogi by self-\nplay with a general reinforcement learning algorithm.\narXiv:1712.01815 , 2017.\nSteven A. Sloman. The empirical case for two systems of\nreasoning. Psychological Bulletin , 119:3\u201322, 1996.\nHaotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and\nChao Zhang. AdaPlanner: Adaptive planning from feed-\nback with language models. In NeurIPS , 2023.\nD\u00b4\u0131dac Sur \u00b4\u0131s, Sachit Menon, and Carl V ondrick. ViperGPT:\nVisual inference via Python execution for reasoning. In\nICCV , 2023.\nMaciej Swiechowski, Konrad Godlewski, Bartosz Sawicki,\nand Jacek Ma\u2019ndziuk. Monte Carlo tree search: A re-\nview of recent modifications and applications. Artificial\nIntelligence Review , 56:2497\u20132562, 2021.\nHugo Touvron, Louis Martin, Kevin R. Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-\nlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, Daniel M. Bikel, Lukas Blecher, Cristian Cant \u00b4on\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Is-\nabel M. Kloumann, A. V . Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana\nLiskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin\nNie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta,\nKalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael\nSmith, R. Subramanian, Xia Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Rodriguez,\nRobert Stojnic, Sergey Edunov, and Thomas Scialom.\n12", "start_char_idx": 2266, "end_char_idx": 4902, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "509c4d17-0f51-4517-8b28-f67c18e0d647": {"__data__": {"id_": "509c4d17-0f51-4517-8b28-f67c18e0d647", "embedding": null, "metadata": {"page_label": "13", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aed5982e-2f0e-42e1-b4da-f3a8846242a3", "node_type": "4", "metadata": {"page_label": "13", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "d16cd307e48d87690ae35c22a72c59059874e617bd04b3aa82061f38a1844f7f", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nLlama 2: Open foundation and fine-tuned chat models.\narXiv:2307.09288 , 2023.\nTom V odopivec, Spyridon Samothrakis, and Branko Ster.\nOn Monte Carlo tree search and reinforcement learning.\nJournal of Artificial Intelligence Research , 60:881\u2013936,\n2017.\nGuanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar,\nChaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anand-\nkumar. V oyager: An open-ended embodied agent with\nlarge language models. arXiv:2305.16291 , 2023.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou. Self-consistency improves\nchain of thought reasoning in language models. In ICLR ,\n2022.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of\nthought prompting elicits reasoning in large language\nmodels. In NeurIPS , 2022.\nMichael Wooldridge and Nicholas R Jennings. Intelligent\nagents: Theory and practice. The Knowledge Engineering\nReview , 10:115 \u2013 152, 1995.\nPhilipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter\nAbbeel, and Ken Goldberg. Daydreamer: World models\nfor physical robot learning. In CoRL , 2023.\nYuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-\nYen Kan, Junxian He, and Qizhe Xie. Decomposition\nenhances reasoning via self-evaluation guided decoding.\narXiv:2305.00633 , 2023.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam W Cohen, Ruslan Salakhutdinov, and Christo-\npher D Manning. HotpotQA: A dataset for diverse, ex-\nplainable multi-hop question answering. In EMNLP ,\n2018.\nShunyu Yao, Howard Chen, John Yang, and Karthik R\nNarasimhan. WebShop: Towards scalable real-world web\ninteraction with grounded language agents. In NeurIPS ,\n2022.\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\nThomas L. Griffiths, Yuan Cao, and Karthik Narasimhan.\nTree of thoughts: deliberate problem solving with large\nlanguage models. In NeurIPS , 2023a.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,\nKarthik Narasimhan, and Yuan Cao. ReAct: Synergizing\nreasoning and acting in language models. In ICLR , 2023b.\nWeirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel,\nand Yang Gao. Mastering Atari games with limited data.\nInNeurIPS , 2021.Denny Zhou, Nathanael Sch \u00a8arli, Le Hou, Jason Wei, Nathan\nScales, Xuezhi Wang, Dale Schuurmans, Olivier Bous-\nquet, Quoc Le, and Ed Chi. Least-to-most prompting\nenables complex reasoning in large language models. In\nICLR , 2022.\nYuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor\nBursztyn, Ryan A. Rossi, Somdeb Sarkhel, and Chao\nZhang. ToolChain*: Efficient action space navigation in\nlarge language models with A* search. In ICLR , 2023.\n13", "start_char_idx": 0, "end_char_idx": 2688, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89d7228a-693e-4105-b451-74acd9731121": {"__data__": {"id_": "89d7228a-693e-4105-b451-74acd9731121", "embedding": null, "metadata": {"page_label": "14", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0175c01-e7bf-4881-a84c-17fc03176bb0", "node_type": "4", "metadata": {"page_label": "14", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "1edab3e982242d767a2b0dd73374e8093d4f851cc46a313a8725a95ac06a5f91", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2638edf1-fb56-4b40-ae1e-873292b4ec32", "node_type": "1", "metadata": {}, "hash": "8d38d653057700fd07805b27be665758b93c6ff5d81667e44e67fb45d2dcd077", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nAppendix of LATS\nThe appendix is organized as follows. First in Sec. A, we\nshow the pseudocode of our proposed algorithm, LATS. In\nSec. B, we provide further discussion of the limitations of\nour method. In Sec. C, we present additional experimental\nresults. In Sec. D, we specify the environment details in our\nexperiments. Finally, we list our prompts used for the three\nenvironments in Sec. E (HotPotQA), Sec. F (Programming),\nand Sec. G (WebShop), respectively.\nA. LATS Pseudocode\nAlg. 1 shows the pseudocode of our algorithm LATS. Nodes\nare stored explicitly in the memory. Unless otherwise speci-\nfied, in all experiments, we set the number of sampled nodes\nton= 5 and the exploration weight to w= 1. We use\na self-consistency weight of \u03bb= 0.5for HotPotQA and\nGame of 24, and \u03bb= 0.8for Programming and WebShop.\nB. More Discussion on Limitations\nAs stated in Sec. 6, LATS has two main limitations:\nComputational cost. Although LATS can improve rea-\nsoning and decision-making, this arrives at a higher com-\nputational cost relative to simpler prompting methods like\nReAct or Reflexion. However, the following facts serve as\nmitigations to this issue:\n\u2022Asymptotically, our method has the same sample com-\nplexity as ToT (Yao et al., 2023a) and RAP (Hao et al.,\n2023), but achieves better performance, expands fewer\nnodes, and uses fewer tokens on average upon success.\nThis suggests that our method is not only stronger\nin problem-solving but also has higher efficiency. A\nfull analysis of the cost can be found in Tab. 9 in Ap-\npendix C.\n\u2022The number of nodes nexpanded at every step provides\na natural trade-off between performance and efficiency.\nIn fact, setting n= 1 makes the method as efficient\nas ReAct (Yao et al., 2023b) with multiple trials or\nCoT-SC (Wang et al., 2022).\nIn general, we recommend using LATS for difficult tasks\nlike programming or for situations where performance is\nprioritized over efficiency in practice. We hope that contin-\nued advancements in LMs will reduce costs and increase\nthe applicability of LATS.\nAdditionally, there exists a minor cost from querying the en-\nvironment, which we find to be trivial for the environments\nwe study. Most LM-based environments involve API-based\ntools, which are inexpensive and fast to use. It is also worthnoting that this is cheaper than the inference cost associ-\nated with using LMs as world models, as in previous search\napproaches (Hao et al., 2023; Liu et al., 2023).\nAssumption of environment reversion in decision-\nmaking. Since our method is based on Monte Carlo\nTree Search and is model-free, one limitation of LATS on\ndecision-making tasks is that it requires the agent to be\nable to revert to earlier states in the environments. How-\never, this reversion property is feasible in many real-world\nenvironments and applications (despite being not univer-\nsally applicable in all possible environments), including\nprogramming (HumanEval (Chen et al., 2021)), web search\n(WebShop (Yao et al., 2022)), text-based manipulation tasks\n(Alfworld (Shridhar et al., 2020)), and LMs with tool use\n(ToolBench (Qin et al., 2024)). Therefore, we believe that\nleveraging the reversion property is not a shortcoming but\nrather a feature that has not been explicitly given notice\nby the LM decision-making community \u2013 it opens up new\nopportunities in the emerging LM agent community.\nAdditionally, the benchmarks we use in this paper are rel-\natively simple and focused on decision-making compared\nto the complexity of real-world interactive environments.\nMoreover, some environments might not easily support roll-\nbacks to previous states. However, the design of LATS is\nflexible and can be adjusted to various resource constraints.\nUsing planning-based prompting methods like LATS in\nenvironments like Minecraft (Fan et al., 2022) and more rea-\nsoning benchmarks would be interesting avenues for future\nwork.\nC. Additional Ablations\nIn this section, we ablate various designs of LATS.", "start_char_idx": 0, "end_char_idx": 4039, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2638edf1-fb56-4b40-ae1e-873292b4ec32": {"__data__": {"id_": "2638edf1-fb56-4b40-ae1e-873292b4ec32", "embedding": null, "metadata": {"page_label": "14", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0175c01-e7bf-4881-a84c-17fc03176bb0", "node_type": "4", "metadata": {"page_label": "14", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "1edab3e982242d767a2b0dd73374e8093d4f851cc46a313a8725a95ac06a5f91", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89d7228a-693e-4105-b451-74acd9731121", "node_type": "1", "metadata": {"page_label": "14", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "6ef6a27cbb37d6d4d04998ca6708cf7922b88954c1983019360c4f9660d254ef", "class_name": "RelatedNodeInfo"}}, "text": "Therefore, we believe that\nleveraging the reversion property is not a shortcoming but\nrather a feature that has not been explicitly given notice\nby the LM decision-making community \u2013 it opens up new\nopportunities in the emerging LM agent community.\nAdditionally, the benchmarks we use in this paper are rel-\natively simple and focused on decision-making compared\nto the complexity of real-world interactive environments.\nMoreover, some environments might not easily support roll-\nbacks to previous states. However, the design of LATS is\nflexible and can be adjusted to various resource constraints.\nUsing planning-based prompting methods like LATS in\nenvironments like Minecraft (Fan et al., 2022) and more rea-\nsoning benchmarks would be interesting avenues for future\nwork.\nC. Additional Ablations\nIn this section, we ablate various designs of LATS. Ex-\nperiments are conducted on HotPotQA with a maximum\nofk= 50 trajectories and sampling size of n= 5 and\nHumanEval with a maximum of k= 8trajectories and sam-\npling size of n= 5. The result for HotPotQA is shown in\nTab. 8 and HumanEval in Fig. 3.\nExploration weight. We find that there is lower perfor-\nmance on HotPotQA when the exploration weight win the\nselection formula is decreased to 0.5, suggesting that this\nreduces the effectiveness of the search. Increasing wto2.0\ndoes not lead to a performance improvement, but we tend\nto observe faster convergence. The optimal setting depends\non the particular environment and complexity of the state\nspace.\nDepth. In our main experiments we use a maximum depth\nofd= 7on HotPotQA for all methods, following previous\nwork (Yao et al., 2023b). We ablate the effect on LATS after\nreducing it to d= 4. This results in only a slight drop in\nperformance. We find that most questions can be answered\nwithin four steps, and using a greater number of steps tends\n14", "start_char_idx": 3188, "end_char_idx": 5045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6fb9f7e6-c2de-42e5-a7b5-7c146b5f9991": {"__data__": {"id_": "6fb9f7e6-c2de-42e5-a7b5-7c146b5f9991", "embedding": null, "metadata": {"page_label": "15", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5854a489-b825-47fc-885d-c0c07660a4c8", "node_type": "4", "metadata": {"page_label": "15", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "463edbd8a4e082b899f8752380f1fcf7cc1f5d27fbb40b6554b7a9bb589fd911", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nAlgorithm 1 LATS( s, p\u03b8, pV, pref, d, k, n, w, a, b )\nRequire: Initial state s, action generator p\u03b8, value function pV, reflection generator pref, number of generated actions n,\ndepth limit L, number of roll-outs K, context c, exploration weight w, and value function weight \u03bb\nInitialize action space A, observation space O\nInitialize the state-action value function pV:S\u00d7A7\u2192Rand visit counter N:S7\u2192Nto one\nfork\u21900, . . . , K \u22121do\nfort\u21900, . . . , L \u22121do\nifstnot terminal then \u25b7Expansion & Simulation\nfori\u21901, . . . , n do\nSample a(i)\nt\u223cp\u03b8(st)\nGeto(i)\ntfrom environment, s(i)\nt+1\u2190(c(i)\nt, o(i)\nt, a(i)\nt),c(i)\nt+1\u2190(o(i)\nt, a(i)\nt)\nEvaluate V(i)\nt\u223c\u03bb\u2217pV(s(i)\nt) + (1\u2212\u03bb)\u2217SC(s(i)\nt) \u25b7Evaluation\nV(st)\u2190V(i)\nt\nAdds(i)\ntto children\nend for\nend if\nifstis terminal then \u25b7Reflection\nGetrfrom environment\nifrnot success then\nreflection \u2190pref(ct)\nc\u2190reflection\nend if\nend if\nat\u2190arg max a\u2208e(st)h\nV(st) +wq\nlnN(st)\nN(st+1)i\n\u25b7Selection\nGet corresponding otfrom memory, st+1\u2190(ct, ot, at), ct+1\u2190(ot, at)\nN(st+1)\u2190N(st+1) + 1\nifatis an output action then break\nend for\nT\u2190the actual number of steps\nfort\u2190T\u22121, . . . , 0do \u25b7Backpropagation\nV(st)\u2190V(st)(N(st)\u22121)+r\nN(st)\nend for\nend for\nto force the agent into local minima and rarely improves\nsuccess.\nLM value function. The LM value function scores states\nbased on expected future reward. Without this heuristic,\nthe only signal to guide search would be from environment\nrewards for completed trajectories, which are scarce and\noften binary. When we remove the evaluation operation, we\nobserve a dramatic 0.26drop in performance.\nPerformance over time. To see the effects of increasing\nthe number of trajectories sampled, we change kto different\nvalues. We conduct this experiment on HumanEval, which\nhas a more noticeable difference due to sampling less tra-\njectories. The results are shown in Fig. 3, in which LATS\nscales better with more iterations than Reflexion.\nD. Environment Details\nD.1. HotPotQA\nHotPotQA (Yang et al., 2018) is a question-answering\ndataset that requires reasoning over multiple supporting\ndocuments to answer questions. It contains 113k Wikipedia-based question-answer pairs crafted by crowdworkers to\nbe diverse, multi-hop, and explainable. Questions cover a\nrange of types like entities, locations, dates, and comparison\nof shared properties between two entities. Crowdworkers\nalso provide supporting facts from the documents that justify\nthe answer. We use the HotPotQA benchmark setting with\nall the Wikipedia paragraphs to test retrieval. We use a ran-\ndomly selected subset of 100 questions for our experiments\nand a maximum depth limit of 6. Fig. 4 illustrates how\nReAct and LATS work on an example task of HotPotQA,\nand gives a qualitative example on how LATS outperforms\nReAct on the task. For value function hyperparameters, we\nuse\u03bb= 0.5for the LM score and self-consistency score.\nAction Space. We adopt the Wikipedia web API proposed\nin Yao et al. (2023b), with three types of actions to support\ninteractive information retrieval:\n(1)search [entity ], which returns the first 5 sentences\nfrom the corresponding entity wiki page if it exists,\nor else suggests top-5 similar entities from the Wikipedia\nsearch engine,\n(2)lookup [string ], which returns the next sentence in\n15", "start_char_idx": 0, "end_char_idx": 3323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a460e5ee-9fb6-477d-8a06-ce57d715701e": {"__data__": {"id_": "a460e5ee-9fb6-477d-8a06-ce57d715701e", "embedding": null, "metadata": {"page_label": "16", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "26d8284f-000d-4971-9310-caeddf0a7577", "node_type": "4", "metadata": {"page_label": "16", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "da7227fb871d6b1cfc30f5f1c26af443d956f2e70a47f91338ea778fbf3abdc5", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method HotpotQA (EM) \u2191\nLATS ( w= 0.5) 0.55\nLATS ( w= 2.0) 0.63\nLATS ( d= 4) 0.58\nLATS (CoT) 0.62\nLATS (No LM Heuristic) 0.37\nLATS ( w= 1.0,d= 7) 0.63\nTable 11. Ablation results on LATS and baseline variants in Hot-\nPotQA measured by Exact Match (EM). We test different depth d,\nexploration factor w, and versions of LATS using CoT and without\nthe LM value function. We sample n= 5andk= 50 trajectories.\nFigure 3. Performance over successive iterations on HumanEval\nwith GPT-3.5.\nthe page containing string ,\n(3)finish [answer ], which finishes the current task with\nanswer .\nThese API calls and free-form thoughts form the action\nspace for this environment.\nD.2. Programming\nThe HumanEval dataset (Chen et al., 2021) is a collection\nof 164 handwritten programming problems introduced to\nevaluate the functional correctness of models for synthe-\nsizing programs from natural language descriptions. Each\nproblem includes a function signature, docstring descrip-\ntion, reference implementation, and multiple unit tests, with\nan average of 7.7 tests per problem. The programming\ntasks assess comprehension of natural language, reasoning,\nalgorithms, and basic mathematics, at a difficulty level com-\nparable to simple software interview questions. Pass rates\nare evaluated with the pass@k metric, where k samples are\ngenerated per problem and a problem is considered solvedif any sample passes all tests. We use all 164 problems for\nour experiments and a maximum depth limit of 8. For the\nthree questions without sample test cases, we write our own.\nFor value function hyperparameters, we use \u03bb= 0.8for the\nLM score and self-consistency score. For GPT-3.5 we use\nsix internal tests, while for GPT-4 we use four internal tests.\nThe Mostly Basic Programming Problems (MBPP) (Austin\net al., 2022) benchmark contains 974 short Python functions\ndesigned to evaluate program synthesis techniques. The\ndataset was constructed by crowdsourcing from workers\nwith basic Python knowledge. Each data point consists of\na natural language description of a programming task, a\nreference solution implementation, and three test cases for\nfunctional correctness. The natural language prompts are\ntypically short, one-sentence descriptions. Solutions cover\ncommon programming constructs including mathematical\noperations, list processing, string manipulation, and usage\nof the Python standard library. On average, solutions are 6.8\nlines of code. The dataset is also supplemented with an ad-\nditional set of 426 problems that were manually verified for\nunambiguous specifications, standard function signatures,\nand accurate test cases. We use a randomly selected subset\nof 397 problems for our experiments. For value function\nhyperparameters, we use \u03bb= 0.8for the LM score and\nself-consistency score.\nD.3. WebShop\nWebShop (Yao et al., 2022) is an interactive web-based\nenvironment designed to evaluate agents on grounded\nlanguage understanding and decision-making. It simulates\nan e-commerce shopping task by providing agents with\nover 1 million real-world products scraped from Amazon,\nspanning 5 categories and 113 subcategories. These\nproducts contain rich linguistic information, with an\naverage text length of 262 words and a vocabulary size\nof 224k. In addition, there are over 800k unique product\noptions available for customization. The environment\nrenders webpages in two modes: HTML mode provides\npixel-level observations with interactive elements, while\nsimple mode converts the raw HTML into a structured text\nobservation more amenable for training agents. The action\nspace consists of query searches and button clicks, which\ntransition between 4-page types: search, results, item, and\nitem detail. Instructions are crowdsourced natural language\nspecifying product attributes and options, with a total of 12k\ncollected. Automatic rewards are computed by comparing\nthe product purchased by the agent against the attributes\nand options specified in the instruction, using both lexical\nmatching and semantic similarity metrics.\nThere are two evaluation metrics used in WebShop: (1) Task\nScore defined as (100\u00d7avg. reward ), which captures the\n16", "start_char_idx": 0, "end_char_idx": 4225, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c11f32bc-429e-4a61-a751-8254b8fa7f6a": {"__data__": {"id_": "c11f32bc-429e-4a61-a751-8254b8fa7f6a", "embedding": null, "metadata": {"page_label": "17", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c2d54692-48fd-4f83-b340-3d4132caafe9", "node_type": "4", "metadata": {"page_label": "17", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "ce6352a55051ba680a76d14ed1b841de22e549db95277da0d13a3035f5b02ece", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nFigure 4. Example trajectories on HotPotQA for ReAct ( left) and LATS ( right ). LATS can sample more actions and avoid failure from\nprevious mistakes by evaluating states with an LM to guide the search toward promising areas of the tree.\nType Argument State \u2192Next State\nsearch [Query ] Search \u2192Results\nchoose Back to search \u2217 \u2192 Search\nchoose Prev/Next page Results \u2192Results\nchoose [Product title ] Results \u2192Item\nchoose [Option ] Item \u2192Item\nchoose Desc/Overview Item \u2192Item-Detail\nchoose Previous Item-Detail \u2192Item\nchoose Buy Item \u2192Episode End\nTable 12. Action space of WebShop.\naverage reward obtained across episodes; and (2) Success\nRate (SR) defined as the portion of instructions where r= 1.\nThe reward is calculated based on the number of attributes\nsatisfied by the selected item. We use 50 environments for\nour experiments and a maximum depth limit of 15. For\nvalue function hyperparameters, we use \u03bb= 0.8for the LM\nscore and self-consistency score.\nD.4. Game of 24\nGame of 24 is a mathematical reasoning challenge where\nthe goal is to use basic arithmetic operations to construct\n24 out of 4 numbers. We follow the setup from Yao et al.\n(2023a), where we measure success if the agent produces aPrompt Method Game of 24 (Success Rate) \u2191\nLATS (CoT, \u03bb= 1) 0.40\nLATS (CoT) 0.44\nTable 13. Ablations on \u03bbin Game of 24 with GPT-3.5. \u03bb= 0.5\nused in the main paper outperforms \u03bb= 1, equivalent to removing\nself-consistency, which indicates that the self-consistency score\nimproves the performance of LATS.\ncorrect equation that equals 24 and uses each input number\nonly once. We report success rate over 50 games. We use\nk= 30 iterations and a maximum depth limit of 5. For value\nfunction hyperparameters, we use \u03bb= 0.5for the LM score\nand self-consistency score. Tab. 13 shows the performance\ncomparison between \u03bb= 0.5and\u03bb= 1, which validates\nour design of self-consistency term.\nE. HotPotQA Prompts\nE.1. Base Acting Prompt\nSolve a question answering task with interleaving Thought,\nAction, Observation steps. Thought can reason about the\ncurrent situation, and Action can be three types:\n(1) Search[entity], which searches the exact entity on\nWikipedia and returns the first paragraph if it exists. If\nnot, it will return some similar entities to search.\n17", "start_char_idx": 0, "end_char_idx": 2344, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6000ce40-184d-4264-819c-c27f6e1aef91": {"__data__": {"id_": "6000ce40-184d-4264-819c-c27f6e1aef91", "embedding": null, "metadata": {"page_label": "18", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef18c06e-7007-4105-9222-5e1f2e949bb5", "node_type": "4", "metadata": {"page_label": "18", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "6822e4afcb4e56fc68be15ab3c30d76abb3c7b5007d3505edb6eea8b4cb0a949", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\n(2) Lookup[keyword], which returns the next sentence con-\ntaining keyword in the current passage.\n(3) Finish[answer], which returns the answer and finishes\nthe task.\nAfter each observation, provide the next Thought and next\nAction.\nHere are some examples:\nQuestion: Which magazine was started first Arthur\u2019s Maga-\nzine or First for Women?\nThought 1: I need to search Arthur\u2019s Magazine and First for\nWomen, and find which was started first.\nAction 1: Search[Arthur\u2019s Magazine]\nObservation 1: Arthur\u2019s Magazine was an American literary\nperiodical published in Philadelphia in the 19th century.\nEdited by Timothy Shay Arthur, it featured work by Edgar\nA. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G.\nSpear, and others.[1][2] In May 1846 it was merged into\nGodey\u2019s Lady\u2019s Book.[3]\nThought 2: Arthur\u2019s Magazine was started in 1844. I need\nto search First for Women next.\nAction 2: Search[First for Women]\nObservation 2: First for Women is a woman\u2019s magazine\npublished by Bauer Media Group in the USA.[1] The mag-\nazine was started in 1989. It is based in Englewood Cliffs,\nNew Jersey.[2] In 2011 the circulation of the magazine was\n1,310,696 copies.[3]\nThought 3: First for Women was started in 1989. 1844\n(Arthur\u2019s Magazine) <1989 (First for Women), so Arthur\u2019s\nMagazine was started first.\nAction 3: Finish[Arthur\u2019s Magazine]\n(examples)\nYou have attempted to answer the following question before\nand failed. The following reflection(s) give a plan to avoid\nfailing to answer the question in the same way you did\npreviously. Use them to improve your strategy of correctly\nanswering the given question.\n(trajectories)\n(input)\nE.2. Base Reasoning Prompt\nSolve a question answering task by having a Thought, then\nFinish with your answer. Thought can reason about the\ncurrent situation. Finish[answer] returns the answer and\nfinishes the task. You will be given context that you should\nuse to help you answer the question. Start your responsewith either Action or an indexed Thought\nHere are some examples:\nQuestion: What is the elevation range for the area that the\neastern sector of the Colorado orogeny extends into?\nLet\u2019s think step by step.\nThought 1: The eastern sector of Colorado orogeny extends\ninto the High Plains.\nThought 2: High Plains rise in elevation from around 1,800\nto 7,000 ft\nThought 3: The answer is 1,800 to 7,000 ft.\nAction: Finish[1,800 to 7,000 ft]\n(examples)\nPrevious trial: (trajectories)\n(input)\nE.3. Value Function Prompt\nAnalyze the trajectories of a solution to a question answering\ntask. The trajectories are labeled by environmental Obser-\nvations about the situation, Thoughts that can reason about\nthe current situation, and Actions that can be three types:\n(1) Search[entity], which searches the exact entity on\nWikipedia and returns the first paragraph if it exists. If\nnot, it will return some similar entities to search.\n(2) Lookup[keyword], which returns the next sentence con-\ntaining keyword in the current passage.\n(3) Finish[answer], which returns the answer and finishes\nthe task.\nGiven a question and a trajectory, evaluate its correctness\nand provide your reasoning and analysis in detail. Focus\non the latest thought, action, and observation. Incomplete\ntrajectories can be correct if the thoughts and actions so\nfar are correct, even if the answer is not found yet. Do not\ngenerate additional thoughts or actions. Then at the last line\nconclude \u201cThus the correctness score is s\u201d, where s is an\ninteger from 1 to 10.\nQuestion: Which magazine was started first Arthur\u2019s Maga-\nzine or First for Women?\nThought 1: I need to search Arthur\u2019s Magazine and First for\nWomen, and find which was started first.\nAction 1: Search[Arthur\u2019s Magazine]\nObservation 1: Arthur\u2019s Magazine was an American literary\nperiodical published in Philadelphia in the 19th century.\nEdited by Timothy Shay Arthur, it featured work by Edgar\nA. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G.\n18", "start_char_idx": 0, "end_char_idx": 3996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad010d9f-3b0f-48ac-be5c-1b5e3bab1c2e": {"__data__": {"id_": "ad010d9f-3b0f-48ac-be5c-1b5e3bab1c2e", "embedding": null, "metadata": {"page_label": "19", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fde98b00-085b-4177-8efb-81af16683b7e", "node_type": "4", "metadata": {"page_label": "19", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "62c3f3f1377245a5067d143114fe99c150965d99ead8cb8dcb472fcc4ff732dc", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nSpear, and others.[1][2] In May 1846 it was merged into\nGodey\u2019s Lady\u2019s Book.[3]\nThis trajectory is correct as it is reasonable to search for\nthe first magazine provided in the question. It is also better\nto have simple searches corresponding to a single entity,\nmaking this the best action.\nThus the correctness score is 10\n(other examples)\n(failed trajectories)\n(context)\nE.4. Reflection Prompt\nAnalyze the trajectories of a solution to a question-\nanswering task. The trajectories are labeled by environ-\nmental Observations about the situation, Thoughts that can\nreason about the current situation, and Actions that can be\nthree types:\n(1) Search[entity], which searches the exact entity on\nWikipedia and returns the first paragraph if it exists. If\nnot, it will return some similar entities to search.\n(2) Lookup[keyword], which returns the next sentence con-\ntaining keyword in the current passage.\n(3) Finish[answer], which returns the answer and finishes\nthe task.\nGiven a question and a trajectory, evaluate its correctness\nand provide your reasoning and analysis in detail. Focus\non the latest thought, action, and observation. Incomplete\ntrajectories can be correct if the thoughts and actions so\nfar are correct, even if the answer is not found yet. Do not\ngenerate additional thoughts or actions. Then at the last line\nconclude \u201cThus the correctness score is s\u201d, where s is an\ninteger from 1 to 10.\nQuestion: Which magazine was started first Arthur\u2019s Maga-\nzine or First for Women?\nThought 1: I need to search Arthur\u2019s Magazine and First for\nWomen, and find which was started first.\nAction 1: Search[Arthur\u2019s Magazine]\nObservation 1: Arthur\u2019s Magazine was an American literary\nperiodical published in Philadelphia in the 19th century.\nEdited by Timothy Shay Arthur, it featured work by Edgar\nA. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G.\nSpear, and others.[1][2] In May 1846 it was merged into\nGodey\u2019s Lady\u2019s Book.[3]\nThis trajectory is correct as it is reasonable to search for\nthe first magazine provided in the question. It is also better\nto have simple searches corresponding to a single entity,making this the best action.\nThus the correctness score is 10\n(other examples)\n(failed trajectories)\n(context)\nF. Programming Prompts\nF.1. HumanEval function implementation example\nSample function signature:\nd e f minSubArraySum ( nums ) :\nGiven an a r r a y of i n t e g e r s nums ,\nf i n d t h e minimum sum of any\nnon \u2212empty sub \u2212 a r r a y of nums .\nExample\nminSubArraySum ( [ \u2212 1 , \u22122 , \u22123]) == \u22126\nSample function body implementation:\nmin sum = f l o a t ( \u2019 i n f \u2019 )\nf o r i i n r a n g e ( l e n ( nums ) ) :\nc u r r e n t s u m = 0\nf o r j i n r a n g e ( i , l e n ( nums ) ) :\nc u r r e n t s u m += nums [ j ]\ni f c u r r e n t s u m <min sum :\nmin sum = c u r r e n t s u m\nr e t u r n min sum\nF.2. Base Acting/Reasoning Prompt\nYou are an AI Python assistant. You will be given your\nprevious implementation of a function, a series of unit tests\nresults, and your self-reflection on your previous implemen-\ntation. Write your full implementation (restate the function\nsignature).\nExample 1:\n[previous impl]:\nd e f add ( a : i n t , b : i n t ) \u2212 >i n t :\n\u2018 \u2018 Given i n t e g e r s a and b ,\nr e t u r n t h e t o t a l v a l u e of a and b . \u2019 \u2019\nr e t u r n a \u2212 b\n[unit test results from previous impl]:\nTested passed:\nTests failed:\nassert add(1, 2) == 3 # output: -1\n19", "start_char_idx": 0, "end_char_idx": 3487, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f253fcb-3ebe-4493-86ca-72150c7235a4": {"__data__": {"id_": "4f253fcb-3ebe-4493-86ca-72150c7235a4", "embedding": null, "metadata": {"page_label": "20", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b3ecc0dc-0c1c-4d04-a591-5a4ab9669a31", "node_type": "4", "metadata": {"page_label": "20", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "2bf54c001639c4f093f2c8e504bc607770ccee06c77714fce142e30bfb417fba", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nassert add(1, 2) == 4 # output: -1\n[reflection on previous impl]:\nThe implementation failed the test cases where the input\nintegers are 1 and 2. The issue arises because the code does\nnot add the two integers together, but instead subtracts the\nsecond integer from the first. To fix this issue, we should\nchange the operator from \u2018-\u2019 to \u2018+\u2019 in the return statement.\nThis will ensure that the function returns the correct output\nfor the given input.\n[improved impl]:\nd e f add ( a : i n t , b : i n t ) \u2212 >i n t :\n\u2018 \u2018\nGiven i n t e g e r s a and b ,\nr e t u r n t h e t o t a l v a l u e of a and b .\n\u2019 \u2019\nr e t u r n a + b\nF.3. Reflection Prompt\nYou are a Python programming assistant. You will be given\na function implementation and a series of unit test results.\nYour goal is to write a few sentences to explain why your\nimplementation is wrong, as indicated by the tests. You\nwill need this as guidance when you try again later. Only\nprovide the few sentence description in your answer, not the\nimplementation. You will be given a few examples by the\nuser.\nExample 1:\n[previous impl]:\nd e f add ( a : i n t , b : i n t ) \u2212 >i n t :\n\u2018 \u2018\nGiven i n t e g e r s a and b ,\nr e t u r n t h e t o t a l v a l u e of a and b .\n\u2019 \u2019\nr e t u r n a \u2212 b\n[unit test results from previous impl]:\nTested passed:\nTests failed:\nassert add(1, 2) == 3 # output: -1\nassert add(1, 2) == 4 # output: -1\n[reflection on previous impl]:\nThe implementation failed the test cases where the input\nintegers are 1 and 2. The issue arises because the code does\nnot add the two integers together, but instead subtracts the\nsecond integer from the first. To fix this issue, we should\nchange the operator from \u2018-\u2019 to \u2018+\u2019 in the return statement.This will ensure that the function returns the correct output\nfor the given input.\nF.4. Test Case Generation Prompt\nYou are an AI coding assistant that can write unique, diverse,\nand intuitive unit tests for functions given the signature and\ndocstring.\n(input)\nG. WebShop Prompts\nG.1. Acting Prompt\nWebshop\nInstruction:\ni would like a 3 ounce bottle of bright citrus deodorant for\nsensitive skin, and price lower than 50.00 dollars\n[Search]\nAction: search[3 ounce bright citrus deodorant sensitive\nskin]\nObservation:\n[Back to Search]\nPage 1 (Total results: 50)\n[Next ] [B078GWRC1J]\nBright Citrus Deodorant by Earth Mama \u2014 Natural and Safe\nfor Sensitive Skin, Pregnancy and Breastfeeding, Contains\nOrganic Calendula 3-Ounce\n$10.99\n[B078GTKVXY]\nGinger Fresh Deodorant by Earth Mama \u2014 Natural and Safe\nfor Sensitive Skin, Pregnancy and Breastfeeding, Contains\nOrganic Calendula 3-Ounce\n$10.99\n[B08KBVJ4XN]\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant\nfor Men, Essential Oil-Based Scent, 24-Hour Odor Protec-\ntion, Cedar & Patchouli Blend, Gentle on Sensitive Skin\n(Mountain Sage, 2.7 oz, 2-Pack)\n$15.95\nAction: think[B078GWRC1J and B078GTKVXY are\nbright citrus deodorant less then 50 dollars. I can check\nB078GWRC1J first.]\n20", "start_char_idx": 0, "end_char_idx": 3028, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "963a32c9-d3d7-4b82-b6ef-0d2093049872": {"__data__": {"id_": "963a32c9-d3d7-4b82-b6ef-0d2093049872", "embedding": null, "metadata": {"page_label": "21", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f23543ad-db11-4872-bc28-df3ca2dca110", "node_type": "4", "metadata": {"page_label": "21", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "81eccd6810c7243986aeac5ca096c78dcff7e4317c71543a723baf372d2f5b7d", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nObservation: OK.\nAction: click[B078GWRC1J]\nObservation:\n[Back to Search]\n[Prev]\nscent [assorted scents][bright citrus][calming laven-\nder][ginger fresh][simply non-scents] size [travel set (4-\npack)][3 ounce (pack of 1)][3-ounce (2-pack)] Bright Citrus\nDeodorant by Earth Mama \u2014 Natural and Safe for Sensi-\ntive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\nPrice: $10.99\nRating: N.A.\n[Description]\n[Features]\n[Reviews]\n[Buy Now]\nAction: think[For 3 ounce bottle of bright citrus deodorant\nfor sensitive skin, the item has options \u2018bright citrus\u2019 and \u20183\nounce (pack of 1)\u2019 and seems good to buy.]\nObservation: OK.\nAction: click[bright citrus]\nObservation: You have clicked bright citrus.\nAction: click[3 ounce (pack of 1)]\nObservation: You have clicked 3 ounce (pack of 1).\nAction: click[Buy Now]\nG.2. Value Function Prompt\nGiven an item to purchase and a trajectory that aims to buy\nan item that exactly matches the specification, which cor-\nresponds to the ideal score of 1.0, analyze the following\ntrajectory, then at the last line conclude, \u201cThus the correct-\nness score is s\u201d, where s is an integer from 1 to 10.\nHere are some examples\nWebshop\nInstruction:i am looking for dairy free and apple variety pack of chips,\nand price lower than 30.00 dollars\n[Search]\nAction: search[dairy free and apple variety pack of chips]\nObservation:\n[Back to Search]\nPage 1 (Total results: 50)\n[Next]\n[B07HRFJWP8]\nEnjoy Life Foods Soft Baked Ovals, Breakfast Bars, Nut\nFree Bars, Soy Free, Dairy Free, Non GMO, Gluten Free,\nVegan, Variety Pack, 4 Boxes (20 Bars Total)\n$100.0\n[B01KMHY5PG]\nEnjoy Life Soft Baked Chewy Bars, Variety Pack, Nut Free\nBars, Soy Free, Dairy Free, Gluten Free, 6 Boxes (30 Total\nBars)\n$21.49\n[B008D2X8C4]\nEnjoy Life Lentil Chips Variety Pack, Dairy Free Chips, Soy\nFree, Nut Free, Non GMO, Vegan, Gluten Free, 24 Bags\n(0.8 oz)\n$100.0\nAction: think[The first two items are not what I want. The\nthird item is the dairy free and apple variety pack of chips I\nwant.]\nObservation: OK.\nAction: click[B008D2X8C4]\nObservation:\n[Back to Search]\n[Prev]\nflavor name [dill and sour cream][garlic & parmesan][light\nsea salt][margherita pizza][thai chili lime][variety pack] size\n[0.8 ounce (pack of 24)][4 ounce (pack of 12)]\nPrice: $100.0\nRating: N.A.\n[Description]\n[Features]\n21", "start_char_idx": 0, "end_char_idx": 2391, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "977e631c-1538-47f0-9392-bcedf52284a3": {"__data__": {"id_": "977e631c-1538-47f0-9392-bcedf52284a3", "embedding": null, "metadata": {"page_label": "22", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "914f18a0-a852-4a23-968c-e01f6c7acd93", "node_type": "4", "metadata": {"page_label": "22", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "9d498351a691cb60a4887932dec6be9e26ddf02e7877aa965b6794b4e9748235", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a9eedea9-ec49-4386-b2c1-171b170532cb", "node_type": "1", "metadata": {}, "hash": "a485e2ef029424eaef09d4a78db98687af5442d671ed38576578f8d956317c0f", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\n[Reviews]\n[Buy Now]\nAction: think[The item has options \u2018variety pack\u2019 and \u20180.8\nounce (pack of 24)\u2019 and seems good to buy.]\nObservation: OK.\nAction: click[variety pack]\nObservation: You have clicked variety pack.\nAction: click[0.8 ounce (pack of 24)]\nObservation: You have clicked 0.8 ounce (pack of 24).\nAction: click[Buy Now]\nReflection: In this attempt, I was unsuccessful. I acciden-\ntally bought a product that was $100, which is more than my\nbudget of $30. Either way, the initial search results were not\ngood. Next time, I will do search[\u201cvariety pack of chip\u201d;]\nand then check if the results meet the dairy free and the $30\nbudget constraints. I will continue to refine my searches so\nthat I can find more products.\nThus the correctness score is 5\n(input)\nG.3. Reflection Prompt\nYou are an advanced reasoning agent that can improve based\non self-reflection. You will be given a previous reasoning\ntrial in which you were given access to a shopping website\nand a specific type of item to buy. You were given access\nto relevant context and an item to purchase. You were un-\nsuccessful in buying the correct item either because you did\nnot find an item meeting all of the required specifications\nor because you did not select the correct item. The ideal\nscore is 1.0, and anything less is incorrect. In a few sen-\ntences, Diagnose a possible reason for failure and devise a\nnew, concise, high-level plan that aims to mitigate the same\nfailure. Use complete sentences. Here are some examples:\nPrevious Trial Instruction: i am looking for dairy free and\napple variety pack of chips, and price lower than 30.00\ndollars [Search]\nAction: search[dairy free and apple variety pack of chips]\nObservation: [Back to Search] Page 1 (Total results: 50)\n[Next >] [B07HRFJWP8] Enjoy Life Foods Soft Baked\nOvals, Breakfast Bars, Nut Free Bars, Soy Free, Dairy Free,\nNon GMO, Gluten Free, Vegan, Variety Pack, 4 Boxes(20 Bars Total) $100.0 [B01KMHY5PG] Enjoy Life Soft\nBaked Chewy Bars, Variety Pack, Nut Free Bars, Soy Free,\nDairy Free, Gluten Free, 6 Boxes (30 Total Bars) $21.49\n[B008D2X8C4] Enjoy Life Lentil Chips Variety Pack, Dairy\nFree Chips, Soy Free, Nut Free, Non GMO, Vegan, Gluten\nFree, 24 Bags (0.8 oz) $100.0\nAction: think[The first two items are not what I want. The\nthird item is the dairy free and apple variety pack of chips I\nwant.] Observation: OK.\nAction: click[B008D2X8C4] Observation: [Back to Search]\n[<Prev] flavor name [dill and sour cream][garlic & parme-\nsan][light sea salt][margherita pizza][thai chili lime][variety\npack] size [0.8 ounce (pack of 24)][4 ounce (pack of 12)]\nPrice: $100.0 Rating: N.A. [Description] [Features] [Re-\nviews] [Buy Now]\nAction: think[The item has options \u2018variety pack\u2019 and \u20180.8\nounce (pack of 24)\u2019 and seems good to buy.] Observation:\nOK.\nAction: click[variety pack] Observation: You have clicked\nvariety pack.\nAction: click[0.8 ounce (pack of 24)] Observation: You\nhave clicked 0.8 ounce (pack of 24).\nAction: click[Buy Now]\nSTATUS: FAIL\nReflection: In this attempt, I was unsuccessful. I acciden-\ntally bought a product that was $100, which is more than my\nbudget of $30. Either way, the initial search results were not\ngood. Next time, I will do search[\u201cvariety pack of chips\u201d]\nand then check if the results meet the dairy free and the $30\nbudget constraints. I will continue to refine my searches so\nthat I can find more products.", "start_char_idx": 0, "end_char_idx": 3469, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a9eedea9-ec49-4386-b2c1-171b170532cb": {"__data__": {"id_": "a9eedea9-ec49-4386-b2c1-171b170532cb", "embedding": null, "metadata": {"page_label": "22", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "914f18a0-a852-4a23-968c-e01f6c7acd93", "node_type": "4", "metadata": {"page_label": "22", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "9d498351a691cb60a4887932dec6be9e26ddf02e7877aa965b6794b4e9748235", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "977e631c-1538-47f0-9392-bcedf52284a3", "node_type": "1", "metadata": {"page_label": "22", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "9ceed3e96e006679d4c0ca2f3bb9872ad7810620a8b7fc818bf5066b88069c7b", "class_name": "RelatedNodeInfo"}}, "text": "Observation:\nOK.\nAction: click[variety pack] Observation: You have clicked\nvariety pack.\nAction: click[0.8 ounce (pack of 24)] Observation: You\nhave clicked 0.8 ounce (pack of 24).\nAction: click[Buy Now]\nSTATUS: FAIL\nReflection: In this attempt, I was unsuccessful. I acciden-\ntally bought a product that was $100, which is more than my\nbudget of $30. Either way, the initial search results were not\ngood. Next time, I will do search[\u201cvariety pack of chips\u201d]\nand then check if the results meet the dairy free and the $30\nbudget constraints. I will continue to refine my searches so\nthat I can find more products.\nPrevious Trial Instruction: i need gluten free vegetarian\nsmoked peppered bacon - 4 ounce (pack of 2), and price\nlower than 40.00 dollars [Search]\nAction: search[gluten free vegetarian smoked peppered ba-\ncon 4 ounce pack of 2] Observation: [Back to Search] Page\n1 (Total results: 50) [Next >] [B06Y96MXJV] Smoked\nBacon Sea Salt 3-Pack: Smoked Bacon Chipotle, Smoked\nBacon and Onion, Smoked Peppered Bacon - All-Natural\nSea Salts Slowly Smoked Over Alderwood - No Gluten, No\nMSG, Non-GMO (12 total oz.) $29.99 [B06Y96N1KG]\nSpicy Hot Pepper Sea Salt 3-Pack: Ghost Pepper, Jalapeno,\nHabanero - All Natural, Delicious Blends of Peppers & Sea\nSalt - Gluten-Free, Kosher, No MSG, Non-GMO (12 total\noz.) $29.99 [B07GJTKYJQ] Louisville Vegan Jerky - 5\nFlavor Variety Pack, Non-GMO Soy Protein, Gluten-Free\n(Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and\nCarolina BBQ, 3 Ounces) $42.99\n22", "start_char_idx": 2857, "end_char_idx": 4359, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f505be69-9d8e-48b1-9e8f-67412ebb7589": {"__data__": {"id_": "f505be69-9d8e-48b1-9e8f-67412ebb7589", "embedding": null, "metadata": {"page_label": "23", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0953e88-3f26-4e4b-a3c0-b007fecdaabe", "node_type": "4", "metadata": {"page_label": "23", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}, "hash": "f2d64969c7b41dbcbd0152bfe6daa98c531b5016afeda440f188858c919ca5d6", "class_name": "RelatedNodeInfo"}}, "text": "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nAction: think[The first two items are not what I want. The\nthird item is not what I want, but it is the closest one.]\nObservation: OK.\nAction: click[B07GJTKYJQ] Observation: [Back to\nSearch] [ <Prev] Louisville Vegan Jerky - 5 Flavor Variety\nPack, Non-GMO Soy Protein, Gluten-Free (Black Pepper,\nBuffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ,\n3 Ounces) Price: $42.99 Rating: N.A. [Description] [Fea-\ntures] [Reviews] [Buy Now]\nAction: think[The price is too high and it is not what I want.]\nObservation: OK.\nAction: click[ <Prev] Observation: [Back to Search] Page\n1 (Total results: 50) [Next >] [B06Y96MXJV] Smoked\nBacon Sea Salt 3-Pack: Smoked Bacon Chipotle, Smoked\nBacon and Onion, Smoked Peppered Bacon - All-Natural\nSea Salts Slowly Smoked Over Alderwood - No Gluten,\nNo MSG, Non-GMO (12 total oz.) 29.99 [B06Y96N1KG]\nSpicy Hot Pepper Sea Salt 3-Pack: Ghost Pepper, Jalapeno,\nHabanero - All Natural, Delicious Blends of Peppers &\nSea Salt - Gluten-Free, Kosher, No MSG, Non-GMO (12\ntotal oz.) 29.99 [B07GJTKYJQ] Louisville Vegan Jerky - 5\nFlavor Variety Pack, Non-GMO Soy Protein, Gluten-Free\n(Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and\nCarolina BBQ, 3 Ounces) 42.99\nAction: think[The first two items are not what I want.]\nObservation: OK.\nAction: click[Next >] Observation: Invalid action!\nAction: think[I need to refine my search.] Observation: OK.\nAction: click[ <Back to Search] Observation: Invalid ac-\ntion!\nAction: click[Back to Search]\nSTATUS: FAIL\nReflection: In this attempt, I was unsuccessful. The initial\nsearch results were not the products that I was looking for.\nNext time, I will do search[\u201cvegetarian bacon\u201d] for a broader\nsearch. I will check that the new results will fulfill the gluten\nfree and 4 ounce pack of 2 constraints. I will continue to\nrefine my searches so that I can find more products.\nPrevious trial: trajectory Reflection:\u201d\u2019\n23", "start_char_idx": 0, "end_char_idx": 1976, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"ce0bd718-0c7c-4745-8250-f0e66fb55ac2": {"node_ids": ["3ba96f4f-846a-473b-b4a0-36c0172da10b"], "metadata": {"page_label": "1", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "f98d5f19-5433-45fc-af73-d794e240d1c0": {"node_ids": ["db51ee0f-80ec-4d99-95ce-c523d2a9d538", "2e98f203-6e9c-4257-b3a7-490d277f2873"], "metadata": {"page_label": "2", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "3edd1f19-2dd5-4b3a-8df8-01b871c27a11": {"node_ids": ["37402b8d-14af-4dd1-83ee-71951c1d3ad7", "fc6adb26-a88e-40c3-b114-f2f2f0c5cc27"], "metadata": {"page_label": "3", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "67fa196f-a8b8-4de6-ba8d-3e54846b9633": {"node_ids": ["3b2b1760-3113-4d92-ae3b-e8323d57174b", "6ef87599-3af1-4b69-965e-f73164751ab3"], "metadata": {"page_label": "4", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "f2706bea-df39-4f80-86aa-4dc5f11b0fb8": {"node_ids": ["105e3cdb-daa0-4c3d-b231-e0d8de7d0cce"], "metadata": {"page_label": "5", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "b77e1f55-8541-4e3f-99a1-b8291351a5cd": {"node_ids": ["c9e459f8-0a06-435e-a8ce-505af3126b5f", "852e11a7-ab67-4075-8d68-c2d6c2b55af8"], "metadata": {"page_label": "6", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "f023774c-5f55-4b36-a91e-dea71750b815": {"node_ids": ["8eb07a0b-7edc-4691-9764-a0a29c834bef", "10659886-0ef9-43ea-afb7-0010b82cf958"], "metadata": {"page_label": "7", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "8d130e53-1c72-4594-91a2-433794be99f1": {"node_ids": ["288bba33-38ca-4518-b888-332f3a98e9c6", "1ee23d3e-8b32-4c95-aea0-77183a7758f9"], "metadata": {"page_label": "8", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "771b86d3-499e-4e2d-8236-481d001c5321": {"node_ids": ["38d95827-8a0a-4e27-8ca7-16714c16d9b2", "54c39121-74c6-487f-bb8d-44b762ed8155"], "metadata": {"page_label": "9", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "097e4e9a-a6a8-4265-ab4b-9d7d7bfcd85a": {"node_ids": ["bd65e5c4-bc9a-436c-a131-dc5b5dea1b68", "40740452-8307-4437-a79b-e2addd4722fe"], "metadata": {"page_label": "10", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "349050df-91a6-4d50-867d-2d29058055e7": {"node_ids": ["d1977870-c170-4ba1-80b8-c4034c16ea8d", "8c0551c4-cc53-43d7-8f15-487e35f61e98"], "metadata": {"page_label": "11", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "87f8c58f-d6c7-4a3a-9f29-c0566561c1fd": {"node_ids": ["d3f0efb5-cb36-478a-a961-88bb1db140be", "d895e3e6-67c4-4439-89cd-514f65a389ca"], "metadata": {"page_label": "12", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "aed5982e-2f0e-42e1-b4da-f3a8846242a3": {"node_ids": ["509c4d17-0f51-4517-8b28-f67c18e0d647"], "metadata": {"page_label": "13", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "b0175c01-e7bf-4881-a84c-17fc03176bb0": {"node_ids": ["89d7228a-693e-4105-b451-74acd9731121", "2638edf1-fb56-4b40-ae1e-873292b4ec32"], "metadata": {"page_label": "14", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "5854a489-b825-47fc-885d-c0c07660a4c8": {"node_ids": ["6fb9f7e6-c2de-42e5-a7b5-7c146b5f9991"], "metadata": {"page_label": "15", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "26d8284f-000d-4971-9310-caeddf0a7577": {"node_ids": ["a460e5ee-9fb6-477d-8a06-ce57d715701e"], "metadata": {"page_label": "16", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "c2d54692-48fd-4f83-b340-3d4132caafe9": {"node_ids": ["c11f32bc-429e-4a61-a751-8254b8fa7f6a"], "metadata": {"page_label": "17", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "ef18c06e-7007-4105-9222-5e1f2e949bb5": {"node_ids": ["6000ce40-184d-4264-819c-c27f6e1aef91"], "metadata": {"page_label": "18", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "fde98b00-085b-4177-8efb-81af16683b7e": {"node_ids": ["ad010d9f-3b0f-48ac-be5c-1b5e3bab1c2e"], "metadata": {"page_label": "19", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "b3ecc0dc-0c1c-4d04-a591-5a4ab9669a31": {"node_ids": ["4f253fcb-3ebe-4493-86ca-72150c7235a4"], "metadata": {"page_label": "20", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "f23543ad-db11-4872-bc28-df3ca2dca110": {"node_ids": ["963a32c9-d3d7-4b82-b6ef-0d2093049872"], "metadata": {"page_label": "21", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "914f18a0-a852-4a23-968c-e01f6c7acd93": {"node_ids": ["977e631c-1538-47f0-9392-bcedf52284a3", "a9eedea9-ec49-4386-b2c1-171b170532cb"], "metadata": {"page_label": "22", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}, "b0953e88-3f26-4e4b-a3c0-b007fecdaabe": {"node_ids": ["f505be69-9d8e-48b1-9e8f-67412ebb7589"], "metadata": {"page_label": "23", "file_name": "LATS\u8bba\u6587.pdf", "file_path": "data/LATS\u8bba\u6587.pdf", "file_type": "application/pdf", "file_size": 1054882, "creation_date": "2024-06-20", "last_modified_date": "2024-06-20"}}}}